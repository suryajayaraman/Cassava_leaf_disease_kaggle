{"cells":[{"metadata":{},"cell_type":"markdown","source":"## References\n\n1. [plot_confusion_matrix](https://deeplizard.com/learn/video/0LhiS6yu2qQ)\n2. [sklearn metrics example](https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826)\n3. [multi_class_classification](https://towardsdatascience.com/multi-class-classification-extracting-performance-metrics-from-the-confusion-matrix-b379b427a872)"},{"metadata":{},"cell_type":"markdown","source":"## Library imports"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-11-20T07:49:33.361273Z","iopub.status.busy":"2020-11-20T07:49:33.360454Z","iopub.status.idle":"2020-11-20T07:49:38.340877Z","shell.execute_reply":"2020-11-20T07:49:38.340239Z"},"papermill":{"duration":5.000532,"end_time":"2020-11-20T07:49:38.340989","exception":false,"start_time":"2020-11-20T07:49:33.340457","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# append package pathss\nimport sys\nappend_paths = ['../input/pytorch-image-models/pytorch-image-models-master', \n                '../input/image-fmix/FMix-master']\nfor package_path in append_paths:\n    sys.path.append(package_path)\n\n# basic imports\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport itertools\nfrom tqdm.notebook import tqdm\nimport math\n\n# augumentations library\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightnessContrast,ShiftScaleRotate, Cutout, CoarseDropout, \n    IAAAdditiveGaussianNoise, Transpose, MotionBlur, MedianBlur, GaussianBlur, HueSaturationValue\n    )\nimport albumentations as A\nfrom fmix import sample_mask\nimport cv2\n\n# DL library imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nfrom  torch.cuda.amp import autocast, GradScaler\n\n# timm import\nimport timm\n\n# metrics calculation\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n# basic plotting library\nimport matplotlib.pyplot as plt\n\n# interactive plots\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings  \nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Config params"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CFG:\n    # pipeline parameters\n    SEED        = 42\n    NUM_CLASSES = 5\n    TGT_LABEL   = 'label'\n    TRAIN       = True\n    LR_FIND     = False\n    RETRAIN     = False\n    TEST        = False\n    DEBUG       = False\n    N_FOLDS     = 5 \n    N_EPOCHS    = 1 \n    DF_FRAC     = 1  \n    TEST_BATCH_SIZE  = 32\n    TRAIN_BATCH_SIZE = 16\n    SIZE             = [256, 256]\n    NUM_WORKERS      = 4\n    FOLD_TO_TRAIN    = [0] #, 1, 2, 3, 4\n\n    # model parameters\n    MODEL_ARCH  = 'resnext50_32x4d'\n    MODEL_NAME  = 'resnext50_32x4d_v14'\n    WGT_PATH    = '../input/cassava-final-submission-weight-files'\n    WGT_MODEL   = 'resnext50_32x4d_v13'\n\n    # loss fn parameters\n    LOSS_FN     = 'LabelSmoothingCrossEntropy'  #'CrossEntropyLoss'\n    SMOOTHING   = 0.3\n    MIX_PROB    = 0.25\n    \n    # scheduler variables\n    SCHEDULER = 'OneCycleLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'CosineAnnealingWarmRestarts']\n    T_0       = 10 # CosineAnnealingWarmRestarts\n    MAX_LR    = 3e-5\n    MIN_LR    = 1e-6\n\n    # optimizer variables\n    OPTIMIZER     = 'Adam'\n    WEIGHT_DECAY  = 1e-6\n    GRD_ACC_STEPS = 1\n    MAX_GRD_NORM  = 1000\n\n\nTRAIN_PATH = '../input/cassava-leaf-disease-classification/train_images'\nTEST_PATH = '../input/cassava-leaf-disease-classification/test_images'\nNPY_FOLDER = '../input/cassava-npy-train-images/train_npy_images'\nDIR_INPUT = '../input/cassava-leaf-disease-classification'\n\nindex_label_map = {\n                0: \"Cassava Bacterial Blight (CBB)\", \n                1: \"Cassava Brown Streak Disease (CBSD)\",\n                2: \"Cassava Green Mottle (CGM)\", \n                3: \"Cassava Mosaic Disease (CMD)\", \n                4: \"Healthy\"\n                }\n\nclass_names = [value for key,value in index_label_map.items()]","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_no_of_trainable_params(model):\n    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    return total_trainable_params","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seed(CFG.SEED)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset "},{"metadata":{"execution":{"iopub.execute_input":"2020-11-20T07:49:38.578506Z","iopub.status.busy":"2020-11-20T07:49:38.577513Z","iopub.status.idle":"2020-11-20T07:49:38.655931Z","shell.execute_reply":"2020-11-20T07:49:38.657324Z"},"papermill":{"duration":0.140183,"end_time":"2020-11-20T07:49:38.657516","exception":false,"start_time":"2020-11-20T07:49:38.517333","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(f'{DIR_INPUT}/train.csv')\n#train_df[['cls0', 'cls1', 'cls2', 'cls3', 'cls4']] = train_labels = pd.get_dummies(train_df.iloc[:, 1])\ntrain_df['npy_image_id'] = train_df['image_id'].str.replace('jpg', 'npy')\nif CFG.DF_FRAC < 1:\n    train_df = train_df.sample(frac=CFG.DF_FRAC).reset_index(drop=True)\ntrain_labels = train_df.iloc[:, 1].values\nprint(train_df.shape)\ntrain_df.head()\nfolds = StratifiedKFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.SEED)\n\nif CFG.DEBUG == True:\n    pass\n    #folds = train_df.copy()\n    #for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.TGT_LABEL])):\n    #    folds.loc[val_index, 'fold'] = int(n)\n    #folds['fold'] = folds['fold'].astype(int)\n    #print(folds.groupby(['fold', CFG.TGT_LABEL]).size())","execution_count":7,"outputs":[{"output_type":"stream","text":"(21397, 3)\n","name":"stdout"}]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-20T07:49:38.405054Z","iopub.status.busy":"2020-11-20T07:49:38.404138Z","iopub.status.idle":"2020-11-20T07:49:38.407181Z","shell.execute_reply":"2020-11-20T07:49:38.406559Z"},"papermill":{"duration":0.024286,"end_time":"2020-11-20T07:49:38.407297","exception":false,"start_time":"2020-11-20T07:49:38.383011","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['npy_image_id'].values\n        self.labels = df[CFG.TGT_LABEL].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = np.load(f'{NPY_FOLDER}/{self.file_names[idx]}')\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        label = torch.tensor(self.labels[idx]).long()\n        return image, label\n    \n\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['image_id'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}/{file_name}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CFG.DEBUG == True:\n    train_dataset = TrainDataset(train_df, transform=None)\n    for i in range(1):\n        image, label = train_dataset[i]\n        plt.imshow(image)\n        plt.title(f'label: {label}')\n        plt.show() ","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transforms for Augumentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix(data, target, alpha):\n    indices = torch.randperm(data.size(0))\n    shuffled_data = data[indices]\n    shuffled_target = target[indices]\n\n    lam = np.clip(np.random.beta(alpha, alpha),0.3,0.4)\n    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n    new_data = data.clone()\n    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n    # adjust lambda to exactly match pixel ratio\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n    targets = (target, shuffled_target, lam)\n    return new_data, targets\n\ndef fmix(data, targets, alpha, decay_power, shape, max_soft=0.0, reformulate=False):\n    lam, mask = sample_mask(alpha, decay_power, shape, max_soft, reformulate)\n    #mask =torch.tensor(mask, device=device).float()\n    indices = torch.randperm(data.size(0))\n    shuffled_data = data[indices]\n    shuffled_targets = targets[indices]\n    x1 = torch.from_numpy(mask).to(device)*data\n    x2 = torch.from_numpy(1-mask).to(device)*shuffled_data\n    targets=(targets, shuffled_targets, lam)\n    return (x1+x2), targets","execution_count":10,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-20T07:49:38.496406Z","iopub.status.busy":"2020-11-20T07:49:38.495298Z","iopub.status.idle":"2020-11-20T07:49:38.500954Z","shell.execute_reply":"2020-11-20T07:49:38.500432Z"},"papermill":{"duration":0.032811,"end_time":"2020-11-20T07:49:38.501054","exception":false,"start_time":"2020-11-20T07:49:38.468243","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def generate_transforms():\n    train_transforms = Compose([\n            Resize(height=CFG.SIZE[0], width=CFG.SIZE[1]), #RandomResizedCrop(CFG.size, CFG.size),\n            Transpose(p=0.3), VerticalFlip(p=0.3), HorizontalFlip(p=0.3), ShiftScaleRotate(p=0.4),\n            RandomBrightnessContrast(p=0.4), \n            IAAAdditiveGaussianNoise(p=0.3),  # sharpen, affine transform\n            OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3)], p=0.3),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.3),\n            CoarseDropout(p=0.4), Cutout(p=0.4),\n            Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)])\n            # RandomCrop, IAAAdditiveGaussianNoise, RandomResizedCrop(sz,sz),   \n            # CLAHE, ImageCompression, MaskDropout, elastictransform\n            # IAAAffine\n\n    val_transforms = Compose([\n            Resize(height=CFG.SIZE[0], width=CFG.SIZE[1]),\n            Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0), ToTensorV2(p=1.0)])\n\n    test_transforms = Compose([\n            Resize(height=CFG.SIZE[0], width=CFG.SIZE[1]),\n            Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0), ToTensorV2(p=1.0)])\n\n    return {'train_transforms':train_transforms, 'val_transforms':val_transforms, 'test_transform':test_transforms}","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CFG.DEBUG == True:\n    train_dataset = TrainDataset(train_df, transform=generate_transforms()['train_transforms'])\n    for i in range(1):\n        image, label = train_dataset[i]\n        plt.imshow(image[0])\n        plt.title(f'label: {label}')\n        plt.show() ","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# original resnext class\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name=CFG.MODEL_ARCH, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.NUM_CLASSES)\n\n    def forward(self, x):\n        x = self.model(x)\n        # x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        # x = F.dropout(x, 0.25, self.training)\n        return x","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"```python\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name=CFG.MODEL_ARCH, pretrained=False):\n        super().__init__()\n        self.model_ft = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model_ft.fc.in_features\n        \n        # avg pool + Batchnorm + fc layer\n        self.avg_pool = nn.AdaptiveAvgPool2d ((1,1))\n        self.fea_bn = nn.BatchNorm1d(n_features)\n        self.fea_bn.bias.requires_grad_(False)\n        self.logit =  nn.Linear(n_features, CFG.NUM_CLASSES)        \n\n    def forward(self, x):\n        batch_size, _, _, _ = x.shape\n        # forward pass\n        x = self.model_ft.conv1(x)\n        x = self.model_ft.bn1(x)\n        x = self.model_ft.act1(x)\n        x = self.model_ft.maxpool(x)\n        x = self.model_ft.layer1(x)\n        x = self.model_ft.layer2(x)\n        x = self.model_ft.layer3(x)\n        x = self.model_ft.layer4(x)\n        x = self.avg_pool(x).reshape(batch_size, -1)\n        x = self.fea_bn(x)\n        x = self.logit(x)\n        return x\n    \nmodel = CustomResNext(model_name=CFG.MODEL_ARCH, pretrained=True)\ntrain_dataset = TrainDataset(train_df, transform=generate_transforms()['train_transforms'])\ndataloader_train = DataLoader(train_dataset, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\nimages,labels = next(iter(dataloader_train))\nprint(images.shape, labels.shape)\npreds = model(images)\nprint(preds.shape)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"if CFG.DEBUG == True:\n    model = CustomResNext(model_name=CFG.MODEL_ARCH, pretrained=False)\n    train_dataset = TrainDataset(train_df, transform=generate_transforms()['train_transforms'])\n    train_loader = DataLoader(train_dataset, batch_size= 4, shuffle=True,\n                              num_workers=CFG.NUM_WORKERS, pin_memory=True, drop_last=True)\n    for image, label in train_loader:\n        output = model(image)\n        print(output)\n        break","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loss function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelSmoothingCrossEntropy(nn.Module):\n    \"\"\"\n    NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.1):\n        \"\"\"\n        Constructor for the LabelSmoothing module.\n        :param smoothing: label smoothing factor\n        \"\"\"\n        super(LabelSmoothingCrossEntropy, self).__init__()\n        assert smoothing < 1.0\n        self.smoothing = smoothing\n        self.confidence = 1. - smoothing\n\n    def forward(self, x, target):\n        logprobs = F.log_softmax(x, dim=-1)\n        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n        nll_loss = nll_loss.squeeze(1)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Device as cpu or tpu\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\nprint(device)\n\nif CFG.LOSS_FN == 'CrossEntropyLoss':\n    criterion = nn.CrossEntropyLoss()\nelse:\n    criterion = LabelSmoothingCrossEntropy(smoothing=CFG.SMOOTHING)","execution_count":16,"outputs":[{"output_type":"stream","text":"cpu\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Lr_find"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_lr_finder_results(lr_finder): \n    # Create subplot grid\n    fig = make_subplots(rows=1, cols=2)\n    # layout ={'title': 'Lr_finder_result'}\n    \n    # Create a line (trace) for the lr vs loss, gradient of loss\n    trace0 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['smooth_loss'],name='log_lr vs smooth_loss')\n    trace1 = go.Scatter(x=lr_finder['log_lr'], y=lr_finder['grad_loss'],name='log_lr vs loss gradient')\n\n    # Add subplot trace & assign to each grid\n    fig.add_trace(trace0, row=1, col=1);\n    fig.add_trace(trace1, row=1, col=2);\n    #iplot(fig, show_link=False)\n    fig.write_html(CFG.MODEL_NAME + '_lr_find.html');","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_lr(model, optimizer, data_loader, init_value = 1e-8, final_value=100.0, beta = 0.98, num_batches = 200):\n    assert(num_batches > 0)\n    mult = (final_value / init_value) ** (1/num_batches)\n    lr = init_value\n    optimizer.param_groups[0]['lr'] = lr\n    batch_num = 0\n    avg_loss = 0.0\n    best_loss = 0.0\n    smooth_losses = []\n    raw_losses = []\n    log_lrs = []\n    dataloader_it = iter(data_loader)\n    progress_bar = tqdm(range(num_batches))                \n        \n    for idx in progress_bar:\n        batch_num += 1\n        try:\n            images, labels = next(dataloader_it)\n            #print(images.shape)\n        except:\n            dataloader_it = iter(data_loader)\n            images, labels = next(dataloader_it)\n\n        # Move input and label tensors to the default device\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # handle exception in criterion\n        try:\n            # Forward pass\n            y_preds = model(images.float())\n            loss = criterion(y_preds, labels)\n        except:\n            if len(smooth_losses) > 1:\n                grad_loss = np.gradient(smooth_losses)\n            else:\n                grad_loss = 0.0\n            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n            return lr_finder_results \n                    \n        #Compute the smoothed loss\n        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n        smoothed_loss = avg_loss / (1 - beta**batch_num)\n        \n        #Stop if the loss is exploding\n        if batch_num > 1 and smoothed_loss > 50 * best_loss:\n            if len(smooth_losses) > 1:\n                grad_loss = np.gradient(smooth_losses)\n            else:\n                grad_loss = 0.0\n            lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n                                 'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n            return lr_finder_results\n        \n        #Record the best loss\n        if smoothed_loss < best_loss or batch_num==1:\n            best_loss = smoothed_loss\n        \n        #Store the values\n        raw_losses.append(loss.item())\n        smooth_losses.append(smoothed_loss)\n        log_lrs.append(math.log10(lr))\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # print info\n        progress_bar.set_description(f\"loss: {loss.item()},smoothed_loss: {smoothed_loss},lr : {lr}\")\n\n        #Update the lr for the next step\n        lr *= mult\n        optimizer.param_groups[0]['lr'] = lr\n    \n    grad_loss = np.gradient(smooth_losses)\n    lr_finder_results = {'log_lr':log_lrs, 'raw_loss':raw_losses, \n                         'smooth_loss':smooth_losses, 'grad_loss': grad_loss}\n    return lr_finder_results","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if CFG.LR_FIND == True:\n    # create Dataset\n    temp_train_dataset = TrainDataset(train_df, transform=generate_transforms()['train_transforms'])\n    temp_train_dataloader = DataLoader(temp_train_dataset, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n\n    # create model instance\n    # load pretrained weight file, if present\n    if CFG.RETRAIN == True:\n        i_fold = 0\n        checkpoint = torch.load(f'{CFG.WGT_PATH}/{CFG.WGT_MODEL}_fold{i_fold}.pth')\n        model = CustomResNext(model_name=CFG.MODEL_ARCH, pretrained=False)\n        model.to(device)\n        model.load_state_dict(checkpoint['model'])\n        print(f'Model loaded for {CFG.WGT_MODEL}_fold{i_fold}')\n            \n    else:\n        model = CustomResNext(model_name=CFG.MODEL_ARCH, pretrained=True)\n        model.to(device)\n    optimizer = optim.Adam(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr=CFG.MAX_LR)\n    lr_finder_results = find_lr(model, optimizer, temp_train_dataloader)\n    plot_lr_finder_results(lr_finder_results)","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One fold train and validation function"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-20T07:49:38.80578Z","iopub.status.busy":"2020-11-20T07:49:38.804867Z","iopub.status.idle":"2020-11-20T07:49:38.824741Z","shell.execute_reply":"2020-11-20T07:49:38.825868Z"},"papermill":{"duration":0.048245,"end_time":"2020-11-20T07:49:38.826028","exception":false,"start_time":"2020-11-20T07:49:38.777783","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def train_one_fold(i_fold, model, optimizer, scheduler, scaler, dataloader_train, dataloader_valid):\n    train_fold_results = []\n    lr_list = []\n    best_val_acc = 0.0\n    best_epoch = 0\n    \n    for epoch in range(CFG.N_EPOCHS):\n        print('  Epoch {}/{}'.format(epoch + 1, CFG.N_EPOCHS))\n        model.train()\n        tr_loss = 0.0\n            \n        # training iterator\n        tr_iterator = iter(dataloader_train)\n        train_progress_bar = tqdm(range(len(dataloader_train)))\n    \n        for idx in train_progress_bar:\n            try:\n                images, labels = next(tr_iterator)\n                #print(images.shape)\n            except StopIteration:\n                tr_iterator = iter(dataloader_train)\n                images, labels = next(tr_iterator)\n\n            images = images.to(device)\n            labels = labels.to(device)  \n            #print(images.type()) # FloatTensor\n            \n            mix_decision = np.random.rand()\n            if mix_decision < CFG.MIX_PROB:\n                images, labels = fmix(images, labels, alpha=1., decay_power=5., shape=(CFG.SIZE[0],CFG.SIZE[1]))\n            \n            # builtin package to handle automatic mixed precision\n            with autocast():\n                # Forward pass\n                y_preds = model(images.float())            \n                if mix_decision < CFG.MIX_PROB:\n                    loss = criterion(y_preds, labels[0]) * labels[2] + criterion(y_preds, labels[1]) * (1.0 - labels[2])\n                else:\n                    loss = criterion(y_preds, labels)\n                    \n                # Backward pass\n                scaler.scale(loss).backward()\n                tr_loss += loss.item()\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad() \n            \n            # onecyle lr scheduler\n            scheduler.step()\n            \n            \"\"\"\n            if CFG.GRD_ACC_STEPS > 1:\n                loss = loss / CFG.GRD_ACC_STEPS\n            if CFG.APEX:\n                with amp.scale_loss(loss, optimizer) as scaled_loss:\n                    scaled_loss.backward()\n            else:\n                \n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.MAX_GRD_NORM)\n            if (idx + 1) % CFG.GRD_ACC_STEPS == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n            \"\"\"\n\n            lr_list.append(optimizer.state_dict()[\"param_groups\"][0]['lr'])\n            train_progress_bar.set_description(f\"Train_loss: {tr_loss} loss(avg): {tr_loss/(idx+1)}\")\n        \n        # Validate\n        model.eval()\n        val_loss = 0.0\n        val_preds = None\n        val_labels = None\n        valid_iterator = iter(dataloader_valid)\n        valid_progress_bar = tqdm(range(len(dataloader_valid)))\n\n        for idx in valid_progress_bar:\n            try:\n                images, labels = next(valid_iterator)\n            except StopIteration:\n                tr_iterator = iter(dataloader_valid)\n                images, labels = next(valid_iterator)\n            \n            images = images.to(device)\n            labels = labels.to(device)\n\n            if val_labels is None:\n                val_labels = labels.clone()\n            else:\n                val_labels = torch.cat((val_labels, labels), dim=0)\n            \n            with torch.no_grad():\n                y_preds = model(images)\n            \n            loss = criterion(y_preds, labels)\n            val_loss += loss.item()\n            \n            #if CFG.gradient_accumulation_steps > 1:\n            #    loss = loss / CFG.gradient_accumulation_steps\n            preds = torch.softmax(y_preds, dim=1)\n            \n            # store predictions            \n            if val_preds is None:\n                val_preds = preds\n            else:\n                val_preds = torch.cat((val_preds, preds), dim=0)\n                \n            # print to console\n            valid_progress_bar.set_description(f\"val_loss: {val_loss} loss(avg): {val_loss/(idx+1)}\")\n            \n        #scheduler.step() # lr scheduler for CosineAnnearling with Warmrestarts\n        \n        # save predictions\n        val_preds  = np.argmax(val_preds.cpu().data.numpy(), axis=1)\n        val_labels = val_labels.cpu().data.numpy()\n        #print(val_preds.shape, val_labels.shape)\n        # compute accuracy\n        val_score = accuracy_score(val_labels, val_preds)\n        # class wise accuracy, print results\n        cm = confusion_matrix(val_labels, val_preds)\n        class_wise_acc = []\n        for i, val in enumerate(cm):\n            class_wise_acc.append(val[i]/sum(val)*100)\n        print(f\"Fold:{i_fold}, Epoch:{epoch}, Overall accuracy : {val_score * 100.0}, \\\n               Classwise_acc:{class_wise_acc}\")\n        \n        # store results\n        train_fold_results.append({ 'fold': i_fold, 'epoch': epoch, 'train_loss': tr_loss / len(dataloader_train), \n                                    'valid_loss': val_loss / len(dataloader_valid), 'valid_score': val_score,\n                                    'class_wise_acc': class_wise_acc})\n            \n        # save best models        \n        if val_score > best_val_acc:\n            # reset variables\n            best_val_acc = val_score\n            best_epoch = epoch\n                        \n            # save model weights\n            torch.save({'model': model.state_dict(), 'val_preds':val_preds, 'val_labels':val_labels}, \n                        f\"{CFG.MODEL_NAME}_fold_{i_fold}_epoch{epoch}.pth\")\n    \n    print(f\"For Fold {i_fold}, Best validation accuracy of {best_val_acc} was got at epoch {best_epoch}\")                \n    lr_list = np.array(lr_list)\n    np.save(f\"{CFG.MODEL_NAME}_fold{i_fold}_LRlist.npy\", lr_list)\n    return train_fold_results","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training and validation function calls"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-20T07:49:38.870498Z","iopub.status.busy":"2020-11-20T07:49:38.869688Z","iopub.status.idle":"2020-11-20T11:00:03.095416Z","shell.execute_reply":"2020-11-20T11:00:03.096102Z"},"papermill":{"duration":11424.253057,"end_time":"2020-11-20T11:00:03.096334","exception":false,"start_time":"2020-11-20T07:49:38.843277","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"if CFG.TRAIN == True:\n    train_results = []\n\n    for i_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, train_labels)):\n        if i_fold in CFG.FOLD_TO_TRAIN:\n            print(\"Fold {}/{}\".format(i_fold + 1, CFG.N_FOLDS))\n            \n            # create fold data\n            train_data = train_df.iloc[train_idx].reset_index()    \n            valid_data = train_df.iloc[valid_idx].reset_index()\n            print(train_data.shape, valid_data.shape)\n\n            dataset_train = TrainDataset(train_data, transform=generate_transforms()['train_transforms'])\n            dataset_valid = TrainDataset(valid_data, transform=generate_transforms()['val_transforms'])            \n            dataloader_train = DataLoader(dataset_train, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n            dataloader_valid = DataLoader(dataset_valid, batch_size= CFG.TRAIN_BATCH_SIZE, shuffle=True,\n                          num_workers=CFG.NUM_WORKERS, pin_memory=False, drop_last=False)\n\n            # load pretrained weight file\n            if CFG.RETRAIN == True:\n                checkpoint = torch.load(f'{CFG.WGT_PATH}/{CFG.WGT_MODEL}_fold{i_fold}.pth')\n                model = CustomResNext(model_name=CFG.MODEL_ARCH, pretrained=False)\n                model.to(device)\n                model.load_state_dict(checkpoint['model'])\n                print(f'Model loaded for {CFG.WGT_MODEL}_fold{i_fold}')\n            \n            else:\n                model = CustomResNext(model_name=CFG.MODEL_ARCH, pretrained=True)\n                model.to(device)\n\n            # scaler to handle AMP\n            scaler = GradScaler()   \n            \n            if CFG.OPTIMIZER == 'Adam':\n                optimizer = optim.Adam(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr=CFG.MAX_LR)\n            else:\n                optimizer = optim.SGD(model.parameters(), weight_decay=CFG.WEIGHT_DECAY, lr=CFG.MAX_LR, momentum=0.9)\n            \n            if CFG.SCHEDULER == 'OneCycleLR':\n                scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr= CFG.MAX_LR, epochs = CFG.N_EPOCHS, \n                                  steps_per_epoch = len(dataloader_train), pct_start=0.4, div_factor=10, anneal_strategy='cos')\n            else:\n                scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.MIN_LR, last_epoch=-1)\n                \n            train_fold_results = train_one_fold(i_fold, model, optimizer, scheduler, scaler, dataloader_train, dataloader_valid)\n            train_results = train_results + train_fold_results","execution_count":21,"outputs":[{"output_type":"stream","text":"Fold 1/5\n(17117, 4) (4280, 4)\n","name":"stdout"},{"output_type":"stream","text":"Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnext50_32x4d_ra-d733960d.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d_ra-d733960d.pth\n","name":"stderr"},{"output_type":"stream","text":"  Epoch 1/1\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1070.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97456f291a7f45a3bee19166311c0a9b"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-614b6b39ee87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCosineAnnealingWarmRestarts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtrain_fold_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_results\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_fold_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-7433917931d1>\u001b[0m in \u001b[0;36mtrain_one_fold\u001b[0;34m(i_fold, model, optimizer, scheduler, scaler, dataloader_train, dataloader_valid)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"## Plot training results"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_training_results():\n    fig = make_subplots(rows=2, cols=1)\n\n    colors = [\n        ('#d32f2f', '#ef5350'),\n        ('#303f9f', '#5c6bc0'),\n        ('#00796b', '#26a69a'),\n        ('#fbc02d', '#ffeb3b'),\n        ('#5d4037', '#8d6e63'),\n    ]\n\n    for i in range(CFG.N_FOLDS):\n        data = train_results[train_results['fold'] == i]\n\n        fig.add_trace(go.Scatter(x=data['epoch'].values,\n                                 y=data['train_loss'].values,\n                                 mode='lines',\n                                 visible='legendonly' if i > 0 else True,\n                                 line=dict(color=colors[i][0], width=2),\n                                 name='Train loss - Fold #{}'.format(i)),\n                     row=1, col=1)\n\n        fig.add_trace(go.Scatter(x=data['epoch'],\n                                 y=data['valid_loss'].values,\n                                 mode='lines+markers',\n                                 visible='legendonly' if i > 0 else True,\n                                 line=dict(color=colors[i][1], width=2),\n                                 name='Valid loss - Fold #{}'.format(i)),\n                     row=1, col=1)\n\n        fig.add_trace(go.Scatter(x=data['epoch'].values,\n                                 y=data['valid_score'].values,\n                                 mode='lines+markers',\n                                 line=dict(color=colors[i][0], width=2),\n                                 name='Valid score - Fold #{}'.format(i),\n                                 showlegend=False),\n                     row=2, col=1)\n\n    fig.update_layout({\n      \"annotations\": [\n        {\n          \"x\": 0.225, \n          \"y\": 1.0, \n          \"font\": {\"size\": 16}, \n          \"text\": \"Train / valid losses\", \n          \"xref\": \"paper\", \n          \"yref\": \"paper\", \n          \"xanchor\": \"center\", \n          \"yanchor\": \"bottom\", \n          \"showarrow\": False\n        }, \n        {\n          \"x\": 0.775, \n          \"y\": 1.0, \n          \"font\": {\"size\": 16}, \n          \"text\": \"Validation scores\", \n          \"xref\": \"paper\", \n          \"yref\": \"paper\", \n          \"xanchor\": \"center\", \n          \"yanchor\": \"bottom\", \n          \"showarrow\": False\n        }, \n      ]\n    })\n\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"val_preds_0 = np.load('./R18_imagenet_v2_val_preds_0.npy')\nval_labels_0 = np.load('./R18_imagenet_v2_val_labels_0.npy')\n\ncm = confusion_matrix(val_labels_0, val_preds_0)\nprint(cm)\nplt.figure(figsize=(8,8))\nplot_confusion_matrix(cm, classes=class_names, normalize=True)"},{"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2020-11-20T11:00:03.254336Z","iopub.status.busy":"2020-11-20T11:00:03.253434Z","iopub.status.idle":"2020-11-20T11:00:03.279422Z","shell.execute_reply":"2020-11-20T11:00:03.276855Z"},"papermill":{"duration":0.121489,"end_time":"2020-11-20T11:00:03.27957","exception":false,"start_time":"2020-11-20T11:00:03.158081","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"if CFG.TRAIN == True:\n    train_results = pd.DataFrame(train_results)\n    print(train_results)\n    train_results.to_csv('train_results.csv', index=False)\n    best_folds = np.array([train_results[train_results['fold']==x]['valid_score'].max() for x in CFG.FOLD_TO_TRAIN])\n    print(f'Overall CV accuracy : {best_folds.mean()}, std: {best_folds.std()}')\n    plot_training_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Testing function"},{"metadata":{"trusted":true},"cell_type":"code","source":"if CFG.TEST == True:\n    # read submission file\n    submission_df = pd.read_csv(DIR_INPUT + '/sample_submission.csv')\n    submission_df.iloc[:, 1] = 4\n    #print(submission_df.head())\n    submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"if pipeline[\"test\"] == True:\n    # read submission file\n    submission_df = pd.read_csv(DIR_INPUT + '/sample_submission.csv')\n    submission_df.iloc[:, 1] = 0\n    #print(submission_df.head())\n\n\n    # just for debugging purporse, adding 1 more row\n    if submission_df.shape[0] == 1:\n        submission_df = pd.DataFrame([{'image_id': '2216849948.jpg', 'label': 0},{'image_id': '2216849948.jpg', 'label': 0}])\n        submission_df.reset_index(drop=True, inplace=True)\n    #print(submission_df.head())\n\n\n    # Creating test dataset and dataloaders\n    dataset_test = CassavaDataset(df=submission_df, dataset='test', transforms=transforms_test)\n    dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n    \n    \n    # placeholder for final submission csv\n    submissions = None\n\n    \"\"\"\n    1. Iterate and store predictions (one-hot encoded format) of N-folds of model \n    2. Average the predictions of all folds\n    3. argmax of mean one-hot encoded prediction is output\n    \"\"\"\n    for i_fold in range(N_FOLDS):\n        print(f'Inference for {i_fold}th fold')\n        model = CassavaModel(num_classes=5, use_pretrained_weights=False)\n        model.to(device)\n\n        checkpoint = torch.load(f\"{model_cfg['weight_path']}/{model_cfg['model_name']}_fold_{i_fold}.pth\", map_location=device)\n        model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n        model.eval()\n        test_preds = None\n\n        for step, (images, _) in enumerate(dataloader_test):\n            images = images.to(device, dtype=torch.float)\n            with torch.no_grad():\n                outputs = model(images)\n                preds = torch.softmax(outputs, dim=1).data.cpu()\n                if test_preds is None:\n                    test_preds = preds\n                else:\n                    test_preds = torch.cat((test_preds, preds), dim=0)\n\n        # submission_df[['label']] = test_preds.argmax(test_preds, dim=1)\n        # submission_df.to_csv('submission_fold_{}.csv'.format(i_fold), index=False)\n\n        # logits avg\n        if submissions is None:\n            submissions = test_preds / N_FOLDS\n        else:\n            submissions += test_preds / N_FOLDS\n            \n        \n    #print(submissions[:10])\n    # argmax of predictions and write to csv\n    submission_df['label'] = torch.argmax(submissions, dim=1)\n    submission_df.to_csv('submission.csv', index=False)\n    #print(submission_df.head())"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}