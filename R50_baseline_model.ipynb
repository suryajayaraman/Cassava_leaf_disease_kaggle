{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Custom Dataset classes in pytorch\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "k-Fold validation pytorch\n",
    "--\n",
    "1. https://stackoverflow.com/questions/58996242/cross-validation-for-mnist-dataset-with-pytorch-and-sklearn\n",
    "2. https://discuss.pytorch.org/t/i-need-help-in-this-k-fold-cross-validation-implementation/90705/5\n",
    "3. https://github.com/buomsoo-kim/PyTorch-learners-tutorial/blob/master/PyTorch%20Basics/pytorch-datasets-2.ipynb\n",
    "\n",
    "\n",
    "kFold split sklearn\n",
    "--\n",
    "1. sklearn.model_selection.KFold -  normal ordered splits without any shuffle by default. \n",
    "2. sklearn.model_selection.StratifiedKFold - tries to preserve the distribution of each class in each set\n",
    "3. GroupKFold - ensures the group of data is not repeated in any fold; little complex concept\n",
    "4. RepeatedKFold - repeat kfold n times with different random state each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U skorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "#import math\n",
    "#import time\n",
    "#from skimage import io, transform\n",
    "#from typing import Dict\n",
    "#from pathlib import Path\n",
    "\n",
    "# interactive plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from plotly.offline import init_notebook_mode, iplot # download_plotlyjs, plot\n",
    "#import plotly.graph_objs as go\n",
    "#from plotly.subplots import make_subplots\n",
    "#init_notebook_mode(connected=True)\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# sklearn related imports\n",
    "# import skorch #sklearn + pytorch functionalitites\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#import skorch\n",
    "#from skorch.callbacks import Checkpoint\n",
    "#from skorch.callbacks import Freezer\n",
    "#from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'train_img_path': \"cassava-leaf-disease-classification/train_images/\",\n",
    "    'train_csv_path': 'cassava-leaf-disease-classification/train.csv',\n",
    "    \n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet18', 'model_name': \"R18_pretrain_imagenet\",\n",
    "        'lr': 1e-4, 'weight_path': \"\", \n",
    "        'lr_find' : 0, 'train': 1, 'validate': 0,'test': 0 },\n",
    "\n",
    "    'train_data_loader': { 'batch_size': 16, 'shuffle': False, 'num_workers': 4 },\n",
    "    \n",
    "    'val_data_loader': {'batch_size': 16, 'shuffle': False, 'num_workers': 4 },\n",
    "\n",
    "    'test_data_loader': {'batch_size': 32, 'shuffle': False, 'num_workers': 4 },\n",
    "\n",
    "    'train_params': {'train_start_batch_index' : 117001, 'max_num_steps': 11, 'checkpoint_every_n_steps': 5 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_label_map = {\n",
    "                0: \"Cassava Bacterial Blight (CBB)\", \n",
    "                1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "                2: \"Cassava Green Mottle (CGM)\", \n",
    "                3: \"Cassava Mosaic Disease (CMD)\", \n",
    "                4: \"Healthy\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "1. load images into dataset (Dataset class of pytorch maybe)\n",
    "2. split into 5 fold data - scikit learn\n",
    "3. simple network -r18, r50 with last layers changed to 5 lables\n",
    "4. adam optimizer, lr_finder, cross entropy loss\n",
    "5. cv score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_no_of_trainable_params(model):\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    #print(total_trainable_params)\n",
    "    return total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cfg['train_csv_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', 'label'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _BaseKFold.get_n_splits of StratifiedKFold(n_splits=3, random_state=42, shuffle=True)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf.get_n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 split , Train idx len = 14264, Test idx len = 7133\n",
      "1 split , Train idx len = 14265, Test idx len = 7132\n",
      "2 split , Train idx len = 14265, Test idx len = 7132\n"
     ]
    }
   ],
   "source": [
    "split_data = {}\n",
    "for idx, (train_idx, test_idx) in enumerate(skf.split(X,y)):\n",
    "    print (f'{idx} split , Train idx len = {len(train_idx)}, Test idx len = {len(test_idx)}')\n",
    "    split_data['split' + str(idx+1) + '_train'] = np.bincount(y[train_idx])\n",
    "    split_data['split' + str(idx+1) + '_test'] = np.bincount(y[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['split1_train', 'split1_test', 'split2_train', 'split2_test', 'split3_train', 'split3_test'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame.from_dict(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.index = test_df.index.map(index_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split1_train</th>\n",
       "      <th>split1_test</th>\n",
       "      <th>split2_train</th>\n",
       "      <th>split2_test</th>\n",
       "      <th>split3_train</th>\n",
       "      <th>split3_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cassava Bacterial Blight (CBB)</th>\n",
       "      <td>724</td>\n",
       "      <td>363</td>\n",
       "      <td>725</td>\n",
       "      <td>362</td>\n",
       "      <td>725</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cassava Brown Streak Disease (CBSD)</th>\n",
       "      <td>1460</td>\n",
       "      <td>729</td>\n",
       "      <td>1459</td>\n",
       "      <td>730</td>\n",
       "      <td>1459</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cassava Green Mottle (CGM)</th>\n",
       "      <td>1590</td>\n",
       "      <td>796</td>\n",
       "      <td>1591</td>\n",
       "      <td>795</td>\n",
       "      <td>1591</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cassava Mosaic Disease (CMD)</th>\n",
       "      <td>8772</td>\n",
       "      <td>4386</td>\n",
       "      <td>8772</td>\n",
       "      <td>4386</td>\n",
       "      <td>8772</td>\n",
       "      <td>4386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthy</th>\n",
       "      <td>1718</td>\n",
       "      <td>859</td>\n",
       "      <td>1718</td>\n",
       "      <td>859</td>\n",
       "      <td>1718</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     split1_train  split1_test  split2_train  \\\n",
       "Cassava Bacterial Blight (CBB)                724          363           725   \n",
       "Cassava Brown Streak Disease (CBSD)          1460          729          1459   \n",
       "Cassava Green Mottle (CGM)                   1590          796          1591   \n",
       "Cassava Mosaic Disease (CMD)                 8772         4386          8772   \n",
       "Healthy                                      1718          859          1718   \n",
       "\n",
       "                                     split2_test  split3_train  split3_test  \n",
       "Cassava Bacterial Blight (CBB)               362           725          362  \n",
       "Cassava Brown Streak Disease (CBSD)          730          1459          730  \n",
       "Cassava Green Mottle (CGM)                   795          1591          795  \n",
       "Cassava Mosaic Disease (CMD)                4386          8772         4386  \n",
       "Healthy                                      859          1718          859  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7133,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7132,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['split1'] = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7133, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4386\n",
       "4     859\n",
       "2     796\n",
       "1     729\n",
       "0     363\n",
       "Name: split1, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['split1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 363,  729,  796, 4386,  859])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.countplot(data=np.bincount(result[0]), ax=axes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \"\"\"Cassave leaf disease detection dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, idx_list=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            idx_list (list of ints): select only certain rows from csv \n",
    "        \"\"\"\n",
    "        self.cassava_leaf_disease = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        if idx_list != None:\n",
    "            self.cassava_leaf_disease = self.cassava_leaf_disease.iloc[idx_list, :]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cassava_leaf_disease)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.cassava_leaf_disease.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform != None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = np.array(self.cassava_leaf_disease.iloc[idx, 1])\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassava_train_dataset = CassavaDataset( csv_file=cfg['train_csv_path'],\n",
    "                                        root_dir=cfg['train_img_path'],\n",
    "                                        transform=train_transforms, idx_list=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cassava_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cassava_train_dataset)):\n",
    "    print(cassava_train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INSTANCES = len(cassava_train_dataset)\n",
    "TEST_RATIO = 0.3\n",
    "VAL_SIZE = int(NUM_INSTANCES * 0.3)\n",
    "TRAIN_SIZE = NUM_INSTANCES - VAL_SIZE\n",
    "print(NUM_INSTANCES, TRAIN_SIZE, VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = torch.utils.data.random_split(cassava_train_dataset, (TRAIN_SIZE, VAL_SIZE))\n",
    "print(len(train_ds), len(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = Checkpoint(f_params='best_model.pt', monitor='valid_acc_best')\n",
    "freezer = Freezer(lambda x: not x.startswith('model.fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    PretrainedModel, \n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=0.001,\n",
    "    max_epochs=5,\n",
    "    module__output_features=5,\n",
    "    optimizer=optim.Adam,\n",
    "    iterator_train__shuffle=cfg['train_data_loader']['shuffle'],\n",
    "    iterator_train__num_workers= cfg['train_data_loader']['num_workers'],\n",
    "    iterator_valid__shuffle=cfg['val_data_loader']['shuffle'],\n",
    "    iterator_valid__num_workers=cfg['val_data_loader']['num_workers'],\n",
    "    train_split= predefined_split(val_ds), #skorch.dataset.CVSplit(cv=0.3, stratified=True),\n",
    "    callbacks=[checkpoint, freezer],\n",
    "    device='cuda' # comment to train on cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fit(train_ds, y=None);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "print('1 : ', find_no_of_trainable_params(model))\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "print('2 : ', find_no_of_trainable_params(model))\n",
    "fc_layer = nn.Sequential(nn.Linear(in_features=512, out_features=128), nn.ReLU(),\n",
    "                         nn.Linear(in_features=128, out_features=5))\n",
    "                        #nn.LogSoftmax(dim=1))\n",
    "model.fc = fc_layer\n",
    "print('3 : ', find_no_of_trainable_params(model))\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device, loss fn, optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device);\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs = 1\n",
    "running_loss = 0\n",
    "tr_it = iter(trainloader)\n",
    "progress_bar = tqdm(range(len(trainloader)))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in progress_bar:\n",
    "        try:\n",
    "            inputs, labels = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(trainloader)\n",
    "            inputs, labels = next(tr_it)\n",
    "            \n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss +=loss.item()\n",
    "    \n",
    "        # print info\n",
    "        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {running_loss / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "splits = KFold(n_splits = 5, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for fold, (train_idx, valid_idx) in enumerate(splits.split(CassavaDataset)):\n",
    "    print('Fold : {}'.format(fold))\n",
    "    print(train_idx.shape)\n",
    "    print(valid_idx.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    ".............\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                      WrapperDataset(total_set,  transform=transforms['train']), \n",
    "                      batch_size=64, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "                      WrapperDataset(total_set, transform = transforms['valid']),\n",
    "                      batch_size=64, sampler=valid_sampler)\n",
    "    model.load_state_dict(model_wts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(lyft_kaggle)",
   "language": "python",
   "name": "lyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
