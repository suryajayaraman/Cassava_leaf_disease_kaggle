{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Custom Dataset classes in pytorch\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "k-Fold validation pytorch\n",
    "--\n",
    "1. https://stackoverflow.com/questions/58996242/cross-validation-for-mnist-dataset-with-pytorch-and-sklearn\n",
    "2. https://discuss.pytorch.org/t/i-need-help-in-this-k-fold-cross-validation-implementation/90705/5\n",
    "3. https://github.com/buomsoo-kim/PyTorch-learners-tutorial/blob/master/PyTorch%20Basics/pytorch-datasets-2.ipynb\n",
    "\n",
    "\n",
    "kFold split sklearn\n",
    "--\n",
    "1. sklearn.model_selection.KFold -  normal ordered splits without any shuffle by default. \n",
    "2. sklearn.model_selection.StratifiedKFold - tries to preserve the distribution of each class in each set\n",
    "3. GroupFold - ensures the group of data is not repeated in any fold; little complex concept\n",
    "4. RepeatedKFold - repeat kfold n times with different random state each instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U skorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "#import math\n",
    "#import time\n",
    "#from skimage import io, transform\n",
    "#from typing import Dict\n",
    "#from pathlib import Path\n",
    "\n",
    "# interactive plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from plotly.offline import init_notebook_mode, iplot # download_plotlyjs, plot\n",
    "#import plotly.graph_objs as go\n",
    "#from plotly.subplots import make_subplots\n",
    "#init_notebook_mode(connected=True)\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# sklearn related imports\n",
    "# import skorch #sklearn + pytorch functionalitites\n",
    "# from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import skorch\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.callbacks import Freezer\n",
    "from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'train_img_path': \"cassava-leaf-disease-classification/train_images/\",\n",
    "    'train_csv_path': 'cassava-leaf-disease-classification/train.csv',\n",
    "    \n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet18', 'model_name': \"R18_pretrain_imagenet\",\n",
    "        'lr': 1e-4, 'weight_path': \"\", \n",
    "        'lr_find' : 0, 'train': 1, 'validate': 0,'test': 0 },\n",
    "\n",
    "    'train_data_loader': { 'batch_size': 16, 'shuffle': False, 'num_workers': 4 },\n",
    "    \n",
    "    'val_data_loader': {'batch_size': 16, 'shuffle': False, 'num_workers': 4 },\n",
    "\n",
    "    'test_data_loader': {'batch_size': 32, 'shuffle': False, 'num_workers': 4 },\n",
    "\n",
    "    'train_params': {'train_start_batch_index' : 117001, 'max_num_steps': 11, 'checkpoint_every_n_steps': 5 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_label_map = {\n",
    "                0: \"Cassava Bacterial Blight (CBB)\", \n",
    "                1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "                2: \"Cassava Green Mottle (CGM)\", \n",
    "                3: \"Cassava Mosaic Disease (CMD)\", \n",
    "                4: \"Healthy\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "1. load images into dataset (Dataset class of pytorch maybe)\n",
    "2. split into 5 fold data - scikit learn\n",
    "3. simple network -r18, r50 with last layers changed to 5 lables\n",
    "4. adam optimizer, lr_finder, cross entropy loss\n",
    "5. cv score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_no_of_trainable_params(model):\n",
    "    total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    #print(total_trainable_params)\n",
    "    return total_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \"\"\"Cassave leaf disease detection dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.cassava_leaf_disease = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cassava_leaf_disease)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.cassava_leaf_disease.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = np.array(self.cassava_leaf_disease.iloc[idx, 1])\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassava_train_dataset = CassavaDataset( csv_file=cfg['train_csv_path'],\n",
    "                                        root_dir=cfg['train_img_path'],\n",
    "                                        transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_INSTANCES = len(cassava_train_dataset)\n",
    "TEST_RATIO = 0.3\n",
    "VAL_SIZE = int(NUM_INSTANCES * 0.3)\n",
    "TRAIN_SIZE = NUM_INSTANCES - VAL_SIZE\n",
    "print(NUM_INSTANCES, TRAIN_SIZE, VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = torch.utils.data.random_split(cassava_train_dataset, (TRAIN_SIZE, VAL_SIZE))\n",
    "print(len(train_ds), len(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = Checkpoint(f_params='best_model.pt', monitor='valid_acc_best')\n",
    "freezer = Freezer(lambda x: not x.startswith('model.fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    PretrainedModel, \n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=0.001,\n",
    "    max_epochs=5,\n",
    "    module__output_features=5,\n",
    "    optimizer=optim.Adam,\n",
    "    iterator_train__shuffle=cfg['train_data_loader']['shuffle'],\n",
    "    iterator_train__num_workers= cfg['train_data_loader']['num_workers'],\n",
    "    iterator_valid__shuffle=cfg['val_data_loader']['shuffle'],\n",
    "    iterator_valid__num_workers=cfg['val_data_loader']['num_workers'],\n",
    "    train_split= predefined_split(val_ds), #skorch.dataset.CVSplit(cv=0.3, stratified=True),\n",
    "    callbacks=[checkpoint, freezer],\n",
    "    device='cuda' # comment to train on cpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fit(train_ds, y=None);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "print('1 : ', find_no_of_trainable_params(model))\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "print('2 : ', find_no_of_trainable_params(model))\n",
    "fc_layer = nn.Sequential(nn.Linear(in_features=512, out_features=128), nn.ReLU(),\n",
    "                         nn.Linear(in_features=128, out_features=5))\n",
    "                        #nn.LogSoftmax(dim=1))\n",
    "model.fc = fc_layer\n",
    "print('3 : ', find_no_of_trainable_params(model))\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device, loss fn, optimizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device);\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs = 1\n",
    "running_loss = 0\n",
    "tr_it = iter(trainloader)\n",
    "progress_bar = tqdm(range(len(trainloader)))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in progress_bar:\n",
    "        try:\n",
    "            inputs, labels = next(tr_it)\n",
    "        except StopIteration:\n",
    "            tr_it = iter(trainloader)\n",
    "            inputs, labels = next(tr_it)\n",
    "            \n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss +=loss.item()\n",
    "    \n",
    "        # print info\n",
    "        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {running_loss / (i + 1)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "splits = KFold(n_splits = 5, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for fold, (train_idx, valid_idx) in enumerate(splits.split(CassavaDataset)):\n",
    "    print('Fold : {}'.format(fold))\n",
    "    print(train_idx.shape)\n",
    "    print(valid_idx.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    ".............\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "                      WrapperDataset(total_set,  transform=transforms['train']), \n",
    "                      batch_size=64, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "                      WrapperDataset(total_set, transform = transforms['valid']),\n",
    "                      batch_size=64, sampler=valid_sampler)\n",
    "    model.load_state_dict(model_wts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(lyft_kaggle)",
   "language": "python",
   "name": "lyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
