{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:18.587317Z",
     "iopub.status.busy": "2021-02-18T13:26:18.586370Z",
     "iopub.status.idle": "2021-02-18T13:26:23.846812Z",
     "shell.execute_reply": "2021-02-18T13:26:23.845036Z"
    },
    "papermill": {
     "duration": 5.283332,
     "end_time": "2021-02-18T13:26:23.847064",
     "exception": false,
     "start_time": "2021-02-18T13:26:18.563732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "# basic imports\n",
    "import os\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# augumentations library\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (Compose, Normalize, Resize, CenterCrop)\n",
    "import cv2\n",
    "\n",
    "# DL library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# timm import\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:23.894411Z",
     "iopub.status.busy": "2021-02-18T13:26:23.893637Z",
     "iopub.status.idle": "2021-02-18T13:26:23.940648Z",
     "shell.execute_reply": "2021-02-18T13:26:23.941309Z"
    },
    "papermill": {
     "duration": 0.079753,
     "end_time": "2021-02-18T13:26:23.941521",
     "exception": false,
     "start_time": "2021-02-18T13:26:23.861768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DF :\n",
      "         image_id  label\n",
      "0  1000015157.jpg      0\n",
      "1  1000201771.jpg      3\n",
      "2   100042118.jpg      1\n",
      "3  1000723321.jpg      1\n",
      "4  1000812911.jpg      3\n",
      "TEST_DF :\n",
      "         image_id  label\n",
      "0  2216849948.jpg      4\n"
     ]
    }
   ],
   "source": [
    "# pipeline parameters\n",
    "SEED        = 42\n",
    "NUM_CLASSES = 5\n",
    "TEST_BATCH_SIZE  = 16\n",
    "SIZE             = [512,512]\n",
    "NUM_WORKERS      = 4\n",
    "N_FOLDS          = 5\n",
    "DEBUG            = False\n",
    "\n",
    "# model parameters\n",
    "WGT_PATH    = '../input/cassava-final-submission-weight-files'\n",
    "TEST_PATH   = '../input/cassava-leaf-disease-classification/test_images'\n",
    "TRAIN_PATH  = '../input/cassava-leaf-disease-classification/train_images'\n",
    "\n",
    "print('TRAIN_DF :')\n",
    "train_df = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n",
    "train_df = train_df.loc[0:50,:]\n",
    "print(train_df.head())\n",
    "\n",
    "print('TEST_DF :')\n",
    "test_df  = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:24.378242Z",
     "iopub.status.busy": "2021-02-18T13:26:24.377253Z",
     "iopub.status.idle": "2021-02-18T13:26:24.381357Z",
     "shell.execute_reply": "2021-02-18T13:26:24.382088Z"
    },
    "papermill": {
     "duration": 0.426482,
     "end_time": "2021-02-18T13:26:24.382312",
     "exception": false,
     "start_time": "2021-02-18T13:26:23.955830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:24.420376Z",
     "iopub.status.busy": "2021-02-18T13:26:24.418380Z",
     "iopub.status.idle": "2021-02-18T13:26:24.421122Z",
     "shell.execute_reply": "2021-02-18T13:26:24.421656Z"
    },
    "papermill": {
     "duration": 0.024588,
     "end_time": "2021-02-18T13:26:24.421821",
     "exception": false,
     "start_time": "2021-02-18T13:26:24.397233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_to_str(t, mode='min'):\n",
    "    if mode == 'min':\n",
    "        t = int(t) / 60\n",
    "        hr = t // 60\n",
    "        min = t % 60\n",
    "        return '%2d hr %02d min' % (hr, min)\n",
    "\n",
    "    elif mode == 'sec':\n",
    "        t = int(t)\n",
    "        min = t // 60\n",
    "        sec = t % 60\n",
    "        return '%2d min %02d sec' % (min, sec)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:24.469479Z",
     "iopub.status.busy": "2021-02-18T13:26:24.458425Z",
     "iopub.status.idle": "2021-02-18T13:26:29.723725Z",
     "shell.execute_reply": "2021-02-18T13:26:29.723106Z"
    },
    "papermill": {
     "duration": 5.287767,
     "end_time": "2021-02-18T13:26:29.723888",
     "exception": false,
     "start_time": "2021-02-18T13:26:24.436121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eff_b4_cm = torch.Tensor([\n",
    "                    [0.60537775, 0.06900182, 0.02298651, 0.05426373, 0.24837019],\n",
    "                    [0.04111679, 0.80631433, 0.02512565, 0.04704868, 0.08039455],\n",
    "                    [0.01299001, 0.02053806, 0.78458023, 0.11525486, 0.06663684],\n",
    "                    [0.00136804, 0.00455988, 0.01299577, 0.97013247, 0.01094384],\n",
    "                    [0.06286295, 0.04928953, 0.04346354, 0.07761195, 0.76677203]\n",
    "                    ]).to(device)\n",
    "\n",
    "eff_b3_cm = torch.Tensor([\n",
    "                    [0.5961527, 0.08094956, 0.02852915, 0.04967657, 0.24469201],\n",
    "                    [0.03837288, 0.81133089, 0.02695422, 0.04065599, 0.08268602],\n",
    "                    [0.00922081, 0.01676447, 0.79757024, 0.10561389, 0.07083059],\n",
    "                    [0.00144406, 0.00471191, 0.01497171, 0.96960033, 0.00927199],\n",
    "                    [0.05937232, 0.05239332, 0.04308121, 0.07217732, 0.77297584]\n",
    "                    ]).to(device)\n",
    "\n",
    "vit_cm = torch.Tensor([\n",
    "                    [0.64025282, 0.08276329, 0.0229992 , 0.0496808 , 0.20430389],\n",
    "                    [0.04842168, 0.80996103, 0.02421554, 0.04659624, 0.07080551],\n",
    "                    [0.01550573, 0.02388885, 0.78248467, 0.11231897, 0.06580178],\n",
    "                    [0.00197606, 0.00699218, 0.01276809, 0.97119584, 0.00706782],\n",
    "                    [0.08032061, 0.05781742, 0.05005344, 0.08032664, 0.7314819 ]\n",
    "                    ]).to(device)\n",
    "\n",
    "resnext50_v1_cm = torch.Tensor([\n",
    "                [0.64858158, 0.06347609, 0.01746924, 0.03495962, 0.23551347],\n",
    "                [0.04659624, 0.80539273, 0.02056048, 0.04704868, 0.08040187],\n",
    "                [0.0117339 , 0.02179592, 0.7925309 , 0.10059209, 0.07334719],\n",
    "                [0.00243199, 0.00547185, 0.01390783, 0.9677004 , 0.01048794],\n",
    "                [0.069066  , 0.04656657, 0.04501543, 0.06558215, 0.77376985]\n",
    "                ]).to(device)\n",
    "\n",
    "resnext50_v2_cm = torch.Tensor([\n",
    "                [0.64864499, 0.07078172, 0.02022576, 0.04414662, 0.2162009 ],\n",
    "                [0.05345391, 0.81360563, 0.01919271, 0.04157027, 0.07217747],\n",
    "                [0.01466453, 0.02389148, 0.78247151, 0.1160987 , 0.06287378],\n",
    "                [0.00182391, 0.00440805, 0.01063968, 0.97545261, 0.00767575],\n",
    "                [0.07100474, 0.05199217, 0.0438549 , 0.07140212, 0.76174607]\n",
    "                ]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:29.761625Z",
     "iopub.status.busy": "2021-02-18T13:26:29.760555Z",
     "iopub.status.idle": "2021-02-18T13:26:29.765466Z",
     "shell.execute_reply": "2021-02-18T13:26:29.766354Z"
    },
    "papermill": {
     "duration": 0.027116,
     "end_time": "2021-02-18T13:26:29.766586",
     "exception": false,
     "start_time": "2021-02-18T13:26:29.739470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(resnext50_v1_cm.shape)\n",
    "print(resnext50_v2_cm.shape)\n",
    "print(vit_cm.shape)\n",
    "print(eff_b3_cm.shape)\n",
    "print(eff_b4_cm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:29.817840Z",
     "iopub.status.busy": "2021-02-18T13:26:29.816768Z",
     "iopub.status.idle": "2021-02-18T13:26:29.820351Z",
     "shell.execute_reply": "2021-02-18T13:26:29.819755Z"
    },
    "papermill": {
     "duration": 0.038245,
     "end_time": "2021-02-18T13:26:29.820512",
     "exception": false,
     "start_time": "2021-02-18T13:26:29.782267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class seResNext50Classifier(nn.Module):\n",
    "    def __init__(self, model_arch, pretrained=False):\n",
    "        super(seResNext50Classifier, self).__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ViTBase16Classifier(nn.Module):\n",
    "    def __init__(self, model_arch, pretrained=False):\n",
    "        super(ViTBase16Classifier, self).__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, NUM_CLASSES)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class EfficientnetClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, NUM_CLASSES)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MetaClassifier(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MetaClassifier, self).__init__()\n",
    "        self.layer_1 = nn.Linear(num_feature, 32)\n",
    "        self.layer_2 = nn.Linear(32, 16)\n",
    "        self.layer_3 = nn.Linear(16, 8)\n",
    "        self.layer_out = nn.Linear(8, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(16)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:29.870876Z",
     "iopub.status.busy": "2021-02-18T13:26:29.869965Z",
     "iopub.status.idle": "2021-02-18T13:26:43.055453Z",
     "shell.execute_reply": "2021-02-18T13:26:43.054708Z"
    },
    "papermill": {
     "duration": 13.219606,
     "end_time": "2021-02-18T13:26:43.055618",
     "exception": false,
     "start_time": "2021-02-18T13:26:29.836012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkppoint ok! resnext50_v1_nets 5\n",
      "load checkppoint ok! resnext50_v2_nets 5\n"
     ]
    }
   ],
   "source": [
    "# resnext models\n",
    "renext50_v1_ckpt =  ['resnext50_32x4d_baseline_fold0.pth', 'resnext50_32x4d_baseline_fold1.pth',\n",
    "                     'resnext50_32x4d_baseline_fold2.pth', 'resnext50_32x4d_baseline_fold3.pth',\n",
    "                     'resnext50_32x4d_baseline_fold4.pth']\n",
    "\n",
    "renext50_v2_ckpt =  ['resnext50_baseline_v2_fold0.pth', 'resnext50_baseline_v2_fold1.pth',\n",
    "                     'resnext50_baseline_v2_fold2.pth', 'resnext50_baseline_v2_fold3.pth',\n",
    "                     'resnext50_baseline_v2_fold4.pth']\n",
    "\n",
    "# model instance\n",
    "n = seResNext50Classifier(model_arch = 'resnext50_32x4d', pretrained=False)\n",
    "n.to(device)\n",
    "\n",
    "# v1 model weights\n",
    "resnext50_v1_nets = []\n",
    "for f in renext50_v1_ckpt:\n",
    "    n.load_state_dict(torch.load(f'{WGT_PATH}/{f}')['model'] , strict=True)\n",
    "    resnext50_v1_nets.append(n)\n",
    "print('load checkppoint ok! resnext50_v1_nets', len(resnext50_v1_nets))\n",
    "\n",
    "# v2 model weights\n",
    "resnext50_v2_nets = []\n",
    "for f in renext50_v2_ckpt:\n",
    "    n.load_state_dict(torch.load(f'{WGT_PATH}/{f}')['model'] , strict=True)\n",
    "    resnext50_v2_nets.append(n)\n",
    "print('load checkppoint ok! resnext50_v2_nets', len(resnext50_v2_nets))\n",
    "\n",
    "del n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:26:43.096802Z",
     "iopub.status.busy": "2021-02-18T13:26:43.095904Z",
     "iopub.status.idle": "2021-02-18T13:27:06.830309Z",
     "shell.execute_reply": "2021-02-18T13:27:06.829684Z"
    },
    "papermill": {
     "duration": 23.758235,
     "end_time": "2021-02-18T13:27:06.830475",
     "exception": false,
     "start_time": "2021-02-18T13:26:43.072240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint ok! vit_nets 5\n"
     ]
    }
   ],
   "source": [
    "# Vision transformer models ---\n",
    "vit_ckpt =  ['vit_baseline_fold0.pth', 'vit_baseline_fold1.pth', 'vit_baseline_fold2.pth',\n",
    "             'vit_baseline_fold3.pth', 'vit_baseline_fold4.pth']\n",
    "\n",
    "n = ViTBase16Classifier(model_arch = 'vit_base_patch16_384', pretrained=False)\n",
    "n.to(device)\n",
    "vit_nets = []\n",
    "for f in vit_ckpt:\n",
    "    n.load_state_dict(torch.load(f'{WGT_PATH}/{f}')['model'] , strict=True)\n",
    "    vit_nets.append(n)\n",
    "print('load checkpoint ok! vit_nets', len(vit_nets))\n",
    "del n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:27:06.877656Z",
     "iopub.status.busy": "2021-02-18T13:27:06.876590Z",
     "iopub.status.idle": "2021-02-18T13:27:18.160331Z",
     "shell.execute_reply": "2021-02-18T13:27:18.160954Z"
    },
    "papermill": {
     "duration": 11.313418,
     "end_time": "2021-02-18T13:27:18.161192",
     "exception": false,
     "start_time": "2021-02-18T13:27:06.847774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint ok! efficient_b3_nets 5\n",
      "load checkpoint ok! efficient_b4_nets 5\n"
     ]
    }
   ],
   "source": [
    "# efficient_b3 net weights\n",
    "eff_b3_ckpt =  ['eff_b3_baseline_fold0.pth', 'eff_b3_baseline_fold1.pth', 'eff_b3_baseline_fold2.pth', \n",
    "                'eff_b3_baseline_fold3.pth', 'eff_b3_baseline_fold4.pth']\n",
    "\n",
    "efficient_b3_nets = []\n",
    "n = EfficientnetClassifier(model_arch = 'tf_efficientnet_b3_ns', pretrained=False)\n",
    "n.to(device)\n",
    "for f in eff_b3_ckpt:\n",
    "    n.load_state_dict(torch.load(f'{WGT_PATH}/{f}')['model'] , strict=True)\n",
    "    efficient_b3_nets.append(n)\n",
    "print('load checkpoint ok! efficient_b3_nets', len(efficient_b3_nets))\n",
    "del n\n",
    "\n",
    "# efficient_b4 net weights    \n",
    "eff_b4_ckpt =  ['eff_b4_baseline_fold0.pth', 'eff_b4_baseline_fold1.pth',\n",
    "                'eff_b4_baseline_fold2.pth', 'eff_b4_baseline_fold3.pth',\n",
    "                'eff_b4_baseline_fold4.pth']\n",
    "efficient_b4_nets = []\n",
    "n = EfficientnetClassifier(model_arch = 'tf_efficientnet_b4_ns', pretrained=False)\n",
    "n.to(device)\n",
    "for f in eff_b4_ckpt:\n",
    "    n.load_state_dict(torch.load(f'{WGT_PATH}/{f}')['model'] , strict=True)\n",
    "    efficient_b4_nets.append(n)\n",
    "print('load checkpoint ok! efficient_b4_nets', len(efficient_b4_nets))\n",
    "del n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:27:18.212553Z",
     "iopub.status.busy": "2021-02-18T13:27:18.211379Z",
     "iopub.status.idle": "2021-02-18T13:27:18.216360Z",
     "shell.execute_reply": "2021-02-18T13:27:18.215542Z"
    },
    "papermill": {
     "duration": 0.036987,
     "end_time": "2021-02-18T13:27:18.216527",
     "exception": false,
     "start_time": "2021-02-18T13:27:18.179540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, PATH=TEST_PATH, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['image_id'].values\n",
    "        self.transforms = transforms\n",
    "        self.image_path = PATH\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f\"{self.image_path}/{self.file_names[idx]}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01773,
     "end_time": "2021-02-18T13:27:18.253682",
     "exception": false,
     "start_time": "2021-02-18T13:27:18.235952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "%%time\n",
    "for i in range(100):\n",
    "    temp_img = torch.rand(16,3,512,512)\n",
    "    tf_img = F.interpolate(temp_img, size=[384,384])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:27:18.301364Z",
     "iopub.status.busy": "2021-02-18T13:27:18.300325Z",
     "iopub.status.idle": "2021-02-18T13:27:18.303893Z",
     "shell.execute_reply": "2021-02-18T13:27:18.303344Z"
    },
    "papermill": {
     "duration": 0.032598,
     "end_time": "2021-02-18T13:27:18.304033",
     "exception": false,
     "start_time": "2021-02-18T13:27:18.271435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_transforms = Compose([\n",
    "        Resize(height=SIZE[0], width=SIZE[1]),\n",
    "        #CenterCrop(height=SIZE[0], width=SIZE[1], p=1.0),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0), \n",
    "        ToTensorV2(p=1.0)\n",
    "    ])\n",
    "\n",
    "\n",
    "if DEBUG == True:\n",
    "    dataset = TestDataset(df=train_df, PATH=TRAIN_PATH, transforms = test_transforms)    \n",
    "else:\n",
    "    dataset = TestDataset(df=test_df, PATH=TEST_PATH, transforms = test_transforms)    \n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=TEST_BATCH_SIZE, drop_last=False, \n",
    "                         shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\n",
    "                        #sampler=SequentialSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:27:18.351232Z",
     "iopub.status.busy": "2021-02-18T13:27:18.350166Z",
     "iopub.status.idle": "2021-02-18T13:27:18.353652Z",
     "shell.execute_reply": "2021-02-18T13:27:18.353061Z"
    },
    "papermill": {
     "duration": 0.031887,
     "end_time": "2021-02-18T13:27:18.353804",
     "exception": false,
     "start_time": "2021-02-18T13:27:18.321917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_function(model_list, image):\n",
    "    p = []\n",
    "    for net in model_list: \n",
    "        net.eval()\n",
    "        logit = net(image)\n",
    "        p.append(F.softmax(logit, -1))\n",
    "            \n",
    "        logit = net(torch.flip(image, dims=(2,)).contiguous())\n",
    "        p.append(F.softmax(logit, -1))\n",
    "\n",
    "        logit = net(torch.flip(image, dims=(3,)).contiguous())\n",
    "        p.append(F.softmax(logit, -1))\n",
    "\n",
    "        logit = net(torch.flip(image, dims=(2,3)).contiguous())\n",
    "        p.append(F.softmax(logit, -1))\n",
    "\n",
    "        logit = net(image.permute(0,1,3,2).contiguous())\n",
    "        p.append(F.softmax(logit, -1))\n",
    "        \n",
    "    p = torch.stack(p).mean(0)  ##F.softmax(p,-1)    \n",
    "    #print(p.shape)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:27:18.408550Z",
     "iopub.status.busy": "2021-02-18T13:27:18.399305Z",
     "iopub.status.idle": "2021-02-18T13:27:22.712182Z",
     "shell.execute_reply": "2021-02-18T13:27:22.712941Z"
    },
    "papermill": {
     "duration": 4.340994,
     "end_time": "2021-02-18T13:27:22.713204",
     "exception": false,
     "start_time": "2021-02-18T13:27:18.372210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "estimated time for 15,000 test images = 17 hr 06 min\n",
      "Inference completed\n"
     ]
    }
   ],
   "source": [
    "# start here! ------------------\n",
    "probability = []\n",
    "\n",
    "start_timer = timer()\n",
    "with torch.no_grad():\n",
    "    for t, batch in enumerate(test_loader):\n",
    "        image = batch.to(device)\n",
    "        \n",
    "        # calculate predictions by avging all folds of each model\n",
    "        resnext50_v1_preds = torch.matmul(resnext50_v1_cm, torch.transpose(eval_function(resnext50_v1_nets, image),0,1))\n",
    "        #print(resnext50_v1_preds.shape)\n",
    "        resnext50_v2_preds = torch.matmul(resnext50_v2_cm, torch.transpose(eval_function(resnext50_v2_nets, image),0,1))\n",
    "        efficient_b3_preds = torch.matmul(eff_b3_cm,       torch.transpose(eval_function(efficient_b3_nets, image),0,1))\n",
    "        efficient_b4_preds = torch.matmul(eff_b4_cm,       torch.transpose(eval_function(efficient_b4_nets, image),0,1))\n",
    "        \n",
    "        # change size for vit image\n",
    "        image = F.interpolate(image, size=[384,384])\n",
    "        vit_preds = torch.matmul(vit_cm, torch.transpose(eval_function(vit_nets, image),0,1))\n",
    "        \n",
    "        # add all model predictions\n",
    "        model_avg_preds = resnext50_v1_preds + resnext50_v2_preds + vit_preds + efficient_b3_preds + efficient_b4_preds        \n",
    "        probability.append(model_avg_preds.data.cpu().numpy().transpose())\n",
    "\n",
    "probability = np.concatenate(probability)\n",
    "print(probability.shape)\n",
    "predict = probability.argmax(1)\n",
    "print('estimated time for 15,000 test images = %s'%time_to_str((timer() - start_timer)/len(probability)*15000, 'min'))\n",
    "\n",
    "if DEBUG == True:\n",
    "    image_id = train_df['image_id'].values\n",
    "    df_submit = pd.DataFrame({'image_id': image_id, 'label': predict})\n",
    "    df_submit.to_csv(OUTPUT_DIR+'submission.csv', index=False)\n",
    "    label = train_df['label'].values\n",
    "    correct = (predict == label).mean()\n",
    "    print('correct', correct)\n",
    "    print('probability\\n', probability[:5])\n",
    "    print('predict\\n', predict[:10])\n",
    "\n",
    "else:\n",
    "    image_id = test_df['image_id'].values\n",
    "    df_submit = pd.DataFrame({'image_id': image_id, 'label': predict})\n",
    "    df_submit.to_csv(OUTPUT_DIR+'submission.csv', index=False)\n",
    "    df_submit.head()\n",
    "    print('Inference completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.018475,
     "end_time": "2021-02-18T13:27:22.751422",
     "exception": false,
     "start_time": "2021-02-18T13:27:22.732947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 72.63071,
   "end_time": "2021-02-18T13:27:24.384696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-18T13:26:11.753986",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
