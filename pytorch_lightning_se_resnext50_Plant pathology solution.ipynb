{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretrainedmodels\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 625 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.7.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (0.8.1)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (2.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (4.45.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels) (1.14.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (3.7.4.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (0.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch->pretrainedmodels) (1.18.5)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels) (1.7.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->pretrainedmodels) (8.0.1)\n",
      "Building wheels for collected packages: pretrainedmodels\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60962 sha256=9b2f7af0c68919c89d9ea999836b4db157a29cafa14275ebd3868927c0d4c151\n",
      "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
      "Successfully built pretrainedmodels\n",
      "Installing collected packages: pretrainedmodels\n",
      "Successfully installed pretrainedmodels-0.7.4\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "from time import time\n",
    "import logging\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "from logging import Logger\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import math\n",
    "import gc\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Third party libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    GaussianBlur,\n",
    "    HorizontalFlip,\n",
    "    MedianBlur,\n",
    "    MotionBlur,\n",
    "    Normalize,\n",
    "    OneOf,\n",
    "    RandomBrightness,\n",
    "    RandomContrast,\n",
    "    Resize,\n",
    "    ShiftScaleRotate,\n",
    "    VerticalFlip,\n",
    ")\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# pytorch lightning imports\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# extra installation\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['TORCH_HOME'] = '../input/open-source-weight-files' #setting the environment variable\n",
    "#!echo $TORCH_HOME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants for scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (600, 800, 3)\n",
    "IMAGE_FOLDER = \"../input/cassava-leaf-disease-classification/train_images\"\n",
    "SEED = 42\n",
    "LOG_FOLDER = \"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def mkdir(path: str):\n",
    "    \"\"\"Create directory.\n",
    "\n",
    "     Create directory if it is not exist, else do nothing.\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     path: str\n",
    "        Path of your directory.\n",
    "\n",
    "     Examples\n",
    "     --------\n",
    "     mkdir(\"data/raw/train/\")\n",
    "     \"\"\"\n",
    "    try:\n",
    "        if path is None:\n",
    "            pass\n",
    "        else:\n",
    "            os.stat(path)\n",
    "    except Exception:\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def seed_reproducer(seed=2020):\n",
    "    \"\"\"Reproducer for pytorch experiment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed: int, optional (default = 2019)\n",
    "        Radnom seed.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    seed_reproducer(seed=2019).\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.enabled = True\n",
    "\n",
    "def init_hparams():\n",
    "    parser = ArgumentParser(add_help=False)\n",
    "    parser.add_argument(\"-backbone\", \"--backbone\", type=str, default=\"se_resnext50_32x4d\")\n",
    "    parser.add_argument(\"-tbs\", \"--train_batch_size\", type=int, default=32 * 1)\n",
    "    parser.add_argument(\"-vbs\", \"--val_batch_size\", type=int, default=8 * 1)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=5)\n",
    "    parser.add_argument(\"--image_size\", nargs=\"+\", default=[256, 256])\n",
    "    parser.add_argument(\"--seed\", type=int, default=2020)\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=1)\n",
    "    parser.add_argument(\"--gpus\", nargs=\"+\", default=[0])  # 输入1 2 3\n",
    "    parser.add_argument(\"--precision\", type=int, default=16)\n",
    "    parser.add_argument(\"--gradient_clip_val\", type=float, default=1)\n",
    "    parser.add_argument(\"--soft_labels_filename\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=\"logs_submit\")\n",
    "    try:\n",
    "        hparams = parser.parse_args()\n",
    "    except:\n",
    "        hparams = parser.parse_args([])\n",
    "    print(type(hparams.gpus), hparams.gpus)\n",
    "    if len(hparams.gpus) == 1:\n",
    "        hparams.gpus = [int(hparams.gpus[0])]\n",
    "    else:\n",
    "        hparams.gpus = [int(gpu) for gpu in hparams.gpus]\n",
    "\n",
    "    hparams.image_size = [int(size) for size in hparams.image_size]\n",
    "    return hparams\n",
    "\n",
    "\n",
    "def load_data(frac=1):\n",
    "    train_data = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n",
    "    test_data = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "    # Do fast experiment\n",
    "    if frac < 1:\n",
    "        #logger.info(f\"use frac : {frac}\")\n",
    "        train_data = train_data.sample(frac=frac).reset_index(drop=True)\n",
    "        test_data = test_data.sample(frac=frac).reset_index(drop=True)\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def init_logger(log_name, log_dir=None):\n",
    "    \"\"\"日志模块\n",
    "    Reference: https://juejin.im/post/5bc2bd3a5188255c94465d31\n",
    "    日志器初始化\n",
    "    日志模块功能:\n",
    "        1. 日志同时打印到到屏幕和文件\n",
    "        2. 默认保留近一周的日志文件\n",
    "    日志等级:\n",
    "        NOTSET（0）、DEBUG（10）、INFO（20）、WARNING（30）、ERROR（40）、CRITICAL（50）\n",
    "    如果设定等级为10, 则只会打印10以上的信息\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    log_name : str\n",
    "        日志文件名\n",
    "    log_dir : str\n",
    "        日志保存的目录\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RootLogger\n",
    "        Python日志实例\n",
    "    \"\"\"\n",
    "\n",
    "    mkdir(log_dir)\n",
    "\n",
    "    # 若多处定义Logger，根据log_name确保日志器的唯一性\n",
    "    if log_name not in Logger.manager.loggerDict:\n",
    "        logging.root.handlers.clear()\n",
    "        logger = logging.getLogger(log_name)\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        # 定义日志信息格式\n",
    "        datefmt = \"%Y-%m-%d %H:%M:%S\"\n",
    "        format_str = \"[%(asctime)s] %(filename)s[%(lineno)4s] : %(levelname)s  %(message)s\"\n",
    "        formatter = logging.Formatter(format_str, datefmt)\n",
    "\n",
    "        # 日志等级INFO以上输出到屏幕\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(logging.INFO)\n",
    "        console_handler.setFormatter(formatter)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "        if log_dir is not None:\n",
    "            # 日志等级INFO以上输出到{log_name}.log文件\n",
    "            file_info_handler = TimedRotatingFileHandler(\n",
    "                filename=os.path.join(log_dir, \"%s.log\" % log_name), when=\"D\", backupCount=7\n",
    "            )\n",
    "            file_info_handler.setFormatter(formatter)\n",
    "            file_info_handler.setLevel(logging.INFO)\n",
    "            logger.addHandler(file_info_handler)\n",
    "\n",
    "    logger = logging.getLogger(log_name)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\" 读取图像数据，并转换为RGB格式\n",
    "        32.2 ms ± 2.34 ms -> self\n",
    "        48.7 ms ± 2.24 ms -> plt.imread(image_path)\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    \"\"\" Do normal training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, soft_labels_filename=\"\", \n",
    "                transforms=None, dataset_type = 'train'):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        self.dataset_type = dataset_type\n",
    "        if soft_labels_filename == \"\":\n",
    "            print(\"soft_labels is None\")\n",
    "            self.soft_labels = None\n",
    "        else:\n",
    "            self.soft_labels = pd.read_csv(soft_labels_filename)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_time = time()\n",
    "        # Read image\n",
    "        # solution-1: read from raw image\n",
    "        image_src = f'{IMAGE_FOLDER}/{self.data.loc[index, \"image_id\"]}'\n",
    "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #print(type(image))        \n",
    "        #print(image.shape, labels.shape)\n",
    "\n",
    "        # Convert if not the right shape\n",
    "        #if image.shape != IMG_SHAPE:\n",
    "        #    image = image.transpose(1, 0, 2)\n",
    "\n",
    "        # Do data augmentation\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)[\"image\"].transpose(2, 0, 1)\n",
    "\n",
    "        # Soft label\n",
    "        #if self.soft_labels is not None:\n",
    "        #    label = torch.FloatTensor(\n",
    "        #        (self.data.iloc[index, 1:].values * 0.7).astype(np.float)\n",
    "        #        + (self.soft_labels.iloc[index, 1:].values * 0.3).astype(np.float)\n",
    "        #    )\n",
    "        #else:\n",
    "        #    label = torch.FloatTensor(self.data.iloc[index, 1:].values.astype(np.int64))\n",
    "        \n",
    "        if self.dataset_type == 'train':\n",
    "            label = self.data.loc[index, ['cls0', 'cls1', 'cls2', 'cls3', 'cls4']].values\n",
    "            label = torch.from_numpy(label.astype(np.int8))\n",
    "            #labels = labels.unsqueeze(-1)\n",
    "        else:\n",
    "            labels = torch.Tensor(1)        \n",
    "\n",
    "        return image, label, time() - start_time\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def generate_transforms(image_size):\n",
    "\n",
    "    train_transform = Compose(\n",
    "        [\n",
    "            Resize(height=image_size[0], width=image_size[1]),\n",
    "            OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=1)]),\n",
    "            OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3)], p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            ShiftScaleRotate(\n",
    "                shift_limit=0.2,\n",
    "                scale_limit=0.2,\n",
    "                rotate_limit=20,\n",
    "                interpolation=cv2.INTER_LINEAR,\n",
    "                border_mode=cv2.BORDER_REFLECT_101,\n",
    "                p=1,\n",
    "            ),\n",
    "            Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    val_transform = Compose(\n",
    "        [\n",
    "            Resize(height=image_size[0], width=image_size[1]),\n",
    "            Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"train_transforms\": train_transform, \"val_transforms\": val_transform}\n",
    "\n",
    "\n",
    "def generate_dataloaders(hparams, train_data, val_data, transforms):\n",
    "    train_dataset = PlantDataset(\n",
    "        data=train_data, transforms=transforms[\"train_transforms\"], soft_labels_filename=hparams.soft_labels_filename\n",
    "    )\n",
    "    val_dataset = PlantDataset(\n",
    "        data=val_data, transforms=transforms[\"val_transforms\"], soft_labels_filename=hparams.soft_labels_filename\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=hparams.train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=hparams.num_workers,\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=hparams.val_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=hparams.num_workers,\n",
    "        pin_memory=False)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss_function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossOneHot(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLossOneHot, self).__init__()\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "        #print(preds.shape, labels.shape)\n",
    "        return torch.mean(torch.sum(-labels * self.log_softmax(preds), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_point = torch.load('../input/open-source-weight-files/se_resnext50_32x4d-a260b3a4.pth')\n",
    "#se_resnext_50_imagenet = pretrainedmodels.se_resnext50_32x4d(num_classes=1000,pretrained=None)\n",
    "#se_resnext_50_imagenet.load_state_dict(check_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(input, axis=1):\n",
    "    norm = torch.norm(input, 2, axis, True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "\n",
    "class BinaryHead(nn.Module):\n",
    "    def __init__(self, num_class=5, emb_size=2048, s=16.0):\n",
    "        super(BinaryHead, self).__init__()\n",
    "        self.s = s\n",
    "        self.fc = nn.Sequential(nn.Linear(emb_size, num_class))\n",
    "\n",
    "    def forward(self, fea):\n",
    "        fea = l2_norm(fea)\n",
    "        logit = self.fc(fea) * self.s\n",
    "        return logit\n",
    "\n",
    "\n",
    "class se_resnext50_32x4d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(se_resnext50_32x4d, self).__init__()\n",
    "        check_point = torch.load('../input/open-source-weight-files/se_resnext50_32x4d-a260b3a4.pth')\n",
    "        se_resnext_50_imagenet = pretrainedmodels.se_resnext50_32x4d(num_classes=1000,pretrained=None)\n",
    "        se_resnext_50_imagenet.load_state_dict(check_point)\n",
    "        self.model_ft = nn.Sequential(*list(se_resnext_50_imagenet.children())[:-2])\n",
    "        \n",
    "        #self.model_ft = nn.Sequential(\n",
    "        #    *list(pretrainedmodels.__dict__[\"se_resnext50_32x4d\"](num_classes=1000, pretrained=\"imagenet\",\n",
    "        #            weight_path='../input/open-source-weight-files/se_resnext50_32x4d-a260b3a4.pth').children())[:-2]\n",
    "        #)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.model_ft.last_linear = None\n",
    "        self.fea_bn = nn.BatchNorm1d(2048)\n",
    "        self.fea_bn.bias.requires_grad_(False)\n",
    "        self.binary_head = BinaryHead(5, emb_size=2048, s=1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        img_feature = self.model_ft(x)\n",
    "        img_feature = self.avg_pool(img_feature)\n",
    "        img_feature = img_feature.view(img_feature.size(0), -1)\n",
    "        fea = self.fea_bn(img_feature)\n",
    "        # fea = self.dropout(fea)\n",
    "        output = self.binary_head(fea)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = se_resnext50_32x4d()\n",
    "#print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoolSystem(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "\n",
    "        # 让每次模型初始化一致, 不让只要中间有再次初始化的情况, 结果立马跑偏\n",
    "        seed_reproducer(self.hparams.seed)\n",
    "        self.model = se_resnext50_32x4d()\n",
    "        self.criterion = CrossEntropyLossOneHot()\n",
    "        #self.logger_kun = init_logger(\"kun_in\", hparams.log_dir)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "        #self.scheduler = WarmRestart(self.optimizer, T_max=10, T_mult=1, eta_min=1e-5)\n",
    "        self.scheduler = lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer, T_0=10, T_mult=1, eta_min=1e-5)\n",
    "        return [self.optimizer], [self.scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels,_ = batch\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "        #data_load_time = torch.sum(data_load_time)\n",
    "        # self.logger_kun.info(f\"loss : {loss.item()}\")\n",
    "        # ! can only return scalar tensor in training_step\n",
    "        # must return key -> loss\n",
    "        # optional return key -> progress_bar optional (MUST ALL BE TENSORS)\n",
    "        # optional return key -> log optional (MUST ALL BE TENSORS)\n",
    "        \n",
    "        \n",
    "        # identifying number of correct predections in a given batch\n",
    "        #correct=scores.argmax(dim=1).eq(labels).sum().item()\n",
    "        # identifying total number of labels in a given batch\n",
    "        #total=len(labels)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            #\"data_load_time\": data_load_time,\n",
    "            #\"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(data_load_time.device),\n",
    "            \"scores\": scores, \"labels\": labels,\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # outputs is the return of training_step\n",
    "        train_loss_mean = torch.stack([output[\"loss\"] for output in outputs]).mean()\n",
    "        #self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        #self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        # calculating correect and total predictions\n",
    "        # correct=sum([x[\"correct\"] for  x in outputs])\n",
    "        # total=sum([x[\"total\"] for  x in outputs])\n",
    "        \n",
    "        # compute accuracy\n",
    "        scores_all = torch.argmax(torch.cat([output[\"scores\"] for output in outputs]), dim=1).cpu().detach().numpy()#.astype(int)\n",
    "        labels_all = torch.argmax(torch.cat([output[\"labels\"] for output in outputs]), dim=1).cpu().detach().numpy()\n",
    "        train_acc_score = accuracy_score(labels_all, scores_all)\n",
    "\n",
    "        # logging using tensorboard logger\n",
    "        self.logger.experiment.add_scalar(\"Loss/Train\", train_loss_mean, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar(\"Accuracy_score/Train\", train_acc_score, self.current_epoch)\n",
    "        print(f\"Epoch : {self.current_epoch}, Fold : {self.hparams.fold_i}, train_loss : {train_loss_mean}, train_acc_score: {train_acc_score}\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        step_start_time = time()\n",
    "        images, labels,_ = batch\n",
    "        #data_load_time = torch.sum(data_load_time)\n",
    "        scores = self(images)\n",
    "        loss = self.criterion(scores, labels)\n",
    "\n",
    "        # must return key -> val_loss\n",
    "        return {\n",
    "            \"val_loss\": loss, \"scores\": scores, \"labels\": labels,\n",
    "            #\"data_load_time\": data_load_time,\n",
    "            #\"batch_run_time\": torch.Tensor([time() - step_start_time + data_load_time]).to(data_load_time.device),\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # compute loss\n",
    "        val_loss_mean = torch.stack([output[\"val_loss\"] for output in outputs]).mean()\n",
    "        #self.data_load_times = torch.stack([output[\"data_load_time\"] for output in outputs]).sum()\n",
    "        #self.batch_run_times = torch.stack([output[\"batch_run_time\"] for output in outputs]).sum()\n",
    "\n",
    "        # compute accuracy\n",
    "        scores_all = torch.argmax(torch.cat([output[\"scores\"] for output in outputs]), dim=1).cpu().detach().numpy()#.astype(int)\n",
    "        labels_all = torch.argmax(torch.cat([output[\"labels\"] for output in outputs]), dim=1).cpu().detach().numpy()\n",
    "                \n",
    "        #print('scores_all[0]', scores_all[0], scores_all.shape, type(scores_all))\n",
    "        #print('labels_all[0]', labels_all[0], labels_all.shape, type(labels_all))\n",
    "        val_acc_score = accuracy_score(labels_all, scores_all)\n",
    "        \n",
    "        # logging using tensorboard logger\n",
    "        self.logger.experiment.add_scalar(\"Loss/Validation\", val_loss_mean, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar(\"Accuracy_score/Validation\", val_acc_score, self.current_epoch)\n",
    "\n",
    "        # terminal logs\n",
    "        #self.logger_kun.info(\n",
    "        #    f\"{self.hparams.fold_i}-{self.current_epoch} | \"\n",
    "        #    f\"lr : {self.scheduler.get_lr()[0]:.6f} | \"\n",
    "        #    f\"val_loss : {val_loss_mean:.4f} | \"\n",
    "        #    f\"val_roc_auc : {val_roc_auc:.4f} | \"\n",
    "        #    f\"data_load_times : {self.data_load_times:.2f} | \"\n",
    "        #    f\"batch_run_times : {self.batch_run_times:.2f}\"\n",
    "        #)\n",
    "        # f\"data_load_times : {self.data_load_times:.2f} | \"\n",
    "        # f\"batch_run_times : {self.batch_run_times:.2f}\"\n",
    "        # must return key -> val_loss\n",
    "        \n",
    "        # for EarlyStopping callback\n",
    "        self.log('val_acc_score', val_acc_score)\n",
    "        print(f\"Epoch : {self.current_epoch}, Fold : {self.hparams.fold_i}, val_loss : {val_loss_mean}, val_acc_score: {val_acc_score}\")\n",
    "        #return {\"val_loss\": val_loss_mean, \"val_roc_auc\": val_roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [0]\n",
      "(21397, 7) (21397,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-backbone BACKBONE] [-tbs TRAIN_BATCH_SIZE]\n",
      "                             [-vbs VAL_BATCH_SIZE] [--num_workers NUM_WORKERS]\n",
      "                             [--image_size IMAGE_SIZE [IMAGE_SIZE ...]]\n",
      "                             [--seed SEED] [--max_epochs MAX_EPOCHS]\n",
      "                             [--gpus GPUS [GPUS ...]] [--precision PRECISION]\n",
      "                             [--gradient_clip_val GRADIENT_CLIP_VAL]\n",
      "                             [--soft_labels_filename SOFT_LABELS_FILENAME]\n",
      "                             [--log_dir LOG_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-59d623e6-d9bf-4a5b-86eb-43647aa0063a.json\n",
      "/opt/conda/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:2611: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
     ]
    }
   ],
   "source": [
    "# Make experiment reproducible\n",
    "seed_reproducer(42)\n",
    "\n",
    "# Init Hyperparameters\n",
    "hparams = init_hparams()\n",
    "\n",
    "# init logger\n",
    "#logger = init_logger(\"kun_out\", log_dir=hparams.log_dir)\n",
    "\n",
    "# Load data\n",
    "train_df, test_df = load_data(frac=1)\n",
    "train_df[['cls0', 'cls1', 'cls2', 'cls3', 'cls4']] = train_labels = pd.get_dummies(train_df.iloc[:, 1])\n",
    "train_labels = train_df.iloc[:, 1].values\n",
    "print(train_df.shape, train_labels.shape)\n",
    "\n",
    "# Generate transforms\n",
    "transforms = generate_transforms(hparams.image_size)\n",
    "\n",
    "# Do cross validation\n",
    "valid_roc_auc_scores = []\n",
    "#folds = KFold(n_splits=5, shuffle=True, random_state=hparams.seed)\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "oof_preds = np.zeros((train_df.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_dataset = PlantDataset(train_df)\n",
    "#temp = temp_dataset[0]\n",
    "#temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft_labels is None\n",
      "soft_labels is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Fold : 0, val_loss : 0.85923832654953, val_acc_score: 0.707168894289186\n",
      "Epoch : 0, Fold : 0, train_loss : 0.9188690781593323, train_acc_score: 0.6920919798093101\n",
      "soft_labels is None\n",
      "soft_labels is None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Checkpoint directory /kaggle/working/logs exists and is not empty. With save_top_k=1, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Fold : 1, val_loss : 0.7006984353065491, val_acc_score: 0.7564030659936437\n",
      "Epoch : 0, Fold : 1, train_loss : 0.9351182579994202, train_acc_score: 0.6690344892045985\n"
     ]
    }
   ],
   "source": [
    "for fold_i, (train_index, val_index) in enumerate(folds.split(train_df, train_labels)):\n",
    "    hparams.fold_i = fold_i\n",
    "    train_data = train_df.iloc[train_index, :].reset_index(drop=True)\n",
    "    val_data = train_df.iloc[val_index, :].reset_index(drop=True)\n",
    "    train_dataloader, val_dataloader = generate_dataloaders(hparams, train_data, val_data, transforms)\n",
    "    \n",
    "    # logger function\n",
    "    logger = TensorBoardLogger(LOG_FOLDER + str(fold_i), name=\"se_resnext50_v1\")\n",
    "    \n",
    "    # Define callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val_acc_score\",\n",
    "        filepath=os.path.join(LOG_FOLDER, f\"fold={fold_i}\" + \"-{epoch}-{val_loss:.4f}-{val_acc_score:.4f}\"),\n",
    "                                          save_top_k =1\n",
    "    )\n",
    "    \n",
    "    #early_stop_callback = EarlyStopping(monitor=\"val_roc_auc\", patience=3, mode=\"max\", verbose=True)\n",
    "    \n",
    "    # Instance Model, Trainer and train model\n",
    "    model = CoolSystem(hparams)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=hparams.gpus,\n",
    "        min_epochs=5,\n",
    "        max_epochs=hparams.max_epochs,\n",
    "        #early_stop_callback=early_stop_callback,\n",
    "        #callbacks=[early_stop_callback],\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        precision=hparams.precision,\n",
    "        num_sanity_val_steps=0,\n",
    "        profiler=False,\n",
    "        weights_summary=None,\n",
    "        #use_dp=True,\n",
    "        gradient_clip_val=hparams.gradient_clip_val, \n",
    "        logger=logger\n",
    "    )\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "    #valid_roc_auc_scores.append(round(checkpoint_callback.best, 4))\n",
    "    #logger.info(valid_roc_auc_scores)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
