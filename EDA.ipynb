{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Custom Dataset classes in pytorch\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "\n",
    "Calculating mean and std of custom Dataset\n",
    "\n",
    "https://discuss.pytorch.org/t/computing-the-mean-and-std-of-dataset/34949/3\n",
    "\n",
    "https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560\n",
    "\n",
    "https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "#import math\n",
    "#import time\n",
    "#from skimage import io, transform\n",
    "#from typing import Dict\n",
    "#from pathlib import Path\n",
    "\n",
    "# interactive plot libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from plotly.offline import init_notebook_mode, iplot # download_plotlyjs, plot\n",
    "#import plotly.graph_objs as go\n",
    "#from plotly.subplots import make_subplots\n",
    "#init_notebook_mode(connected=True)\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models.resnet import resnet50, resnet18, resnet34, resnet101\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# sklearn related imports\n",
    "# import skorch #sklearn + pytorch functionalitites\n",
    "from sklearn.model_selection import StratifiedKFold #KFold, \n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#import skorch\n",
    "#from skorch.callbacks import Checkpoint\n",
    "#from skorch.callbacks import Freezer\n",
    "#from skorch.helper import predefined_split\n",
    "#from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cfg = {'train_img_path': \"cassava-leaf-disease-classification/train_images/\",\n",
    "            'train_csv_path': 'cassava-leaf-disease-classification/train.csv',\n",
    "            'train' : True, 'lr_find' : False, 'validate' : True, 'test' : False}\n",
    "\n",
    "model_cfg = {'model_architecture': 'resnet18', 'model_name': 'R18_imagenet',\n",
    "             'init_lr': 1e-4, 'weight_path': '', 'train_epochs':5}\n",
    "\n",
    "train_cfg = {'batch_size': 256, 'shuffle': False, 'num_workers': 4, 'checkpt_every' : 1 }\n",
    "valid_cfg = {'batch_size': 16, 'shuffle': False, 'num_workers': 4, 'validate_every' : 1 }\n",
    "test_cfg  = {'batch_size': 16, 'shuffle': False, 'num_workers': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_label_map = {\n",
    "                0: \"Cassava Bacterial Blight (CBB)\", \n",
    "                1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "                2: \"Cassava Green Mottle (CGM)\", \n",
    "                3: \"Cassava Mosaic Disease (CMD)\", \n",
    "                4: \"Healthy\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('cassava-leaf-disease-classification/train.csv')\n",
    "train_csv['disease'] = train_csv['label'].map(index_label_map);\n",
    "print(train_csv.shape)\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.countplot(y='disease', data=train_csv, ax=axes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_csv['disease'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    \"\"\"Cassave leaf disease detection dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, idx_list=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            idx_list (list of ints): select only certain rows from csv \n",
    "        \"\"\"\n",
    "        self.cassava_leaf_disease = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        if idx_list != None:\n",
    "            self.cassava_leaf_disease = self.cassava_leaf_disease.iloc[idx_list, :]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cassava_leaf_disease)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.cassava_leaf_disease.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform != None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = np.array(self.cassava_leaf_disease.iloc[idx, 1])\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "cassava_dataset = CassavaDataset(csv_file=path_cfg['train_csv_path'], root_dir=path_cfg['train_img_path'], \n",
    "                                 transform=transforms)\n",
    "\n",
    "print(f'Length of total Dataset is ', {len(cassava_dataset)})\n",
    "\n",
    "cassava_dataloader = DataLoader(cassava_dataset, batch_size=train_cfg['batch_size'],shuffle=train_cfg['shuffle'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_it = iter(cassava_dataloader)\n",
    "\n",
    "inputs, labels = next(data_it)\n",
    "inputs = inputs.to(device)\n",
    "inputs.shape\n",
    "inputs = inputs.numpy()\n",
    "temp = np.mean(inputs, axis=(0,2,3))\n",
    "np.std(inputs, axis=(0,2,3))\n",
    "\n",
    "np.std(inputs, axis=(0,2,3), ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = []\n",
    "pop_std0 = []\n",
    "pop_std1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (data, _) in enumerate(cassava_dataloader):\n",
    "    # shape (batch_size, 3, height, width)\n",
    "    numpy_image = data.numpy()\n",
    "    #print(numpy_image.shape)\n",
    "    \n",
    "    # shape (3,)\n",
    "    batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
    "    batch_std0 = np.std(numpy_image, axis=(0,2,3))\n",
    "    batch_std1 = np.std(numpy_image, axis=(0,2,3), ddof=1)\n",
    "    \n",
    "    if idx % 5 == 0 :\n",
    "        print(idx)\n",
    "        \n",
    "    pop_mean.append(batch_mean)\n",
    "    pop_std0.append(batch_std0)\n",
    "    pop_std1.append(batch_std1)\n",
    "\n",
    "pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "pop_std0 = np.array(pop_std0).mean(axis=0)\n",
    "pop_std1 = np.array(pop_std1).mean(axis=0)\n",
    "\n",
    "print(pop_mean, pop_std0, pop_std1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(lyft_kaggle)",
   "language": "python",
   "name": "lyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
