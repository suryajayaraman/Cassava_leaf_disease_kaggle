{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "# metrics calculation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# basic plotting library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # pipeline parameters\n",
    "    SEED        = 42\n",
    "    NUM_CLASSES = 5\n",
    "    TGT_LABEL   = 'label'\n",
    "    N_FOLDS     = 5 \n",
    "    VAL_BATCH_SIZE  = 32\n",
    "    SIZE             = [512,512]\n",
    "    NUM_WORKERS      = 4\n",
    "   \n",
    "    # tf_efficientnet_b3_ns, vit_base_patch16_384, resnext50_32x4d\n",
    "    MODEL_ARCH  = 'tf_efficientnet_b4_ns'           \n",
    "    \n",
    "    # eff_b3_baseline, vit_baseline, resnext50_baseline_v2, , resnext50_32x4d_baseline\n",
    "    WGT_MODEL   = 'eff_b4_baseline'  \n",
    "    \n",
    "\n",
    "TRAIN_PATH = '../input/cassava-leaf-disease-classification/train_images'\n",
    "NPY_FOLDER = '../input/cassava-npy-train-images/train_npy_images'\n",
    "DIR_INPUT  = '../input/cassava-leaf-disease-classification'\n",
    "\n",
    "index_label_map = {\n",
    "                0: \"Cassava Bacterial Blight (CBB)\", \n",
    "                1: \"Cassava Brown Streak Disease (CBSD)\",\n",
    "                2: \"Cassava Green Mottle (CGM)\", \n",
    "                3: \"Cassava Mosaic Disease (CMD)\", \n",
    "                4: \"Healthy\"\n",
    "                }\n",
    "\n",
    "class_names = [value for key,value in index_label_map.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_stats(oof, model_name):\n",
    "        \n",
    "    # foldwise accuracy\n",
    "    #unique_folds = oof.fold.unique()\n",
    "    #for fold in unique_folds:\n",
    "    #    fold_labels = oof[oof['fold']==fold].label.values\n",
    "    #    fold_preds =  np.argmax(oof[oof['fold']==fold].iloc[:, 4:].values, axis=1)\n",
    "    #    print(f\"Fold {fold} acccuracy = {accuracy_score(fold_labels, fold_preds)}\")\n",
    "    \n",
    "    # Overall accuracy\n",
    "    predicted_label = np.argmax(oof.iloc[:, 4:].values, axis=1)\n",
    "    accuracy = accuracy_score(oof['label'].values, predicted_label)\n",
    "    print(f'Accuracy score for {model_name} OOF = {accuracy * 100.0}')\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(predicted_label, oof['label'].values)\n",
    "    class_wise_acc = []\n",
    "    for i, val in enumerate(cm):\n",
    "        class_wise_acc.append(val[i]/sum(val)*100)\n",
    "    print(f\"Classwise_acc for {model_name} = {class_wise_acc}\")\n",
    "    \n",
    "    #plt.figure(figsize=(8,8))\n",
    "    #plot_confusion_matrix(cm, class_names, normalize=True)\n",
    "    #return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 OOF files in input dataset\n",
      "resnext50_32x4d_baseline OOF shape = (21397, 9)\n",
      "resnext50_baseline_v2 OOF shape = (21397, 9)\n",
      "vit_baseline OOF shape = (21397, 9)\n",
      "eff_b3_baseline OOF shape = (21397, 9)\n",
      "eff_b4_baseline OOF shape = (21397, 9)\n"
     ]
    }
   ],
   "source": [
    "oof_dataset_path = 'OOF'\n",
    "model_list = ['resnext50_32x4d_baseline', 'resnext50_baseline_v2', 'vit_baseline', \n",
    "              'eff_b3_baseline', 'eff_b4_baseline'] \n",
    "\n",
    "oof_files = [f'{oof_dataset_path}/{model}_OOF.csv' for model in model_list]\n",
    "print(f'There are {len(oof_files)} OOF files in input dataset')\n",
    "oof_csv = {}\n",
    "for idx,file in enumerate(oof_files):\n",
    "    oof_csv[model_list[idx]] = pd.read_csv(file)\n",
    "\n",
    "for key in oof_csv.keys():\n",
    "    print(f'{key} OOF shape = {oof_csv[key].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fold</th>\n",
       "      <th>files</th>\n",
       "      <th>label</th>\n",
       "      <th>preds0</th>\n",
       "      <th>preds1</th>\n",
       "      <th>preds2</th>\n",
       "      <th>preds3</th>\n",
       "      <th>preds4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12839</td>\n",
       "      <td>3</td>\n",
       "      <td>1000015157.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.148493</td>\n",
       "      <td>0.265875</td>\n",
       "      <td>0.023807</td>\n",
       "      <td>0.281325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8560</td>\n",
       "      <td>2</td>\n",
       "      <td>1000201771.npy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.993812</td>\n",
       "      <td>0.000676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8561</td>\n",
       "      <td>2</td>\n",
       "      <td>100042118.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.320358</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>0.026395</td>\n",
       "      <td>0.618081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4280</td>\n",
       "      <td>1</td>\n",
       "      <td>1000723321.npy</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8562</td>\n",
       "      <td>2</td>\n",
       "      <td>1000812911.npy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.998498</td>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fold           files  label    preds0    preds1    preds2  \\\n",
       "0       12839     3  1000015157.npy      0  0.280500  0.148493  0.265875   \n",
       "1        8560     2  1000201771.npy      3  0.000111  0.003378  0.002023   \n",
       "2        8561     2   100042118.npy      1  0.005702  0.320358  0.029464   \n",
       "3        4280     1  1000723321.npy      1  0.001122  0.986286  0.002689   \n",
       "4        8562     2  1000812911.npy      3  0.000123  0.000193  0.000119   \n",
       "\n",
       "     preds3    preds4  \n",
       "0  0.023807  0.281325  \n",
       "1  0.993812  0.000676  \n",
       "2  0.026395  0.618081  \n",
       "3  0.003097  0.006805  \n",
       "4  0.998498  0.001066  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_csv['eff_b3_baseline'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv0 = oof_csv['resnext50_32x4d_baseline']\n",
    "csv1 = oof_csv['resnext50_baseline_v2']\n",
    "csv2 = oof_csv['vit_baseline']\n",
    "csv3 = oof_csv['eff_b3_baseline']\n",
    "csv4 = oof_csv['eff_b4_baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for resnext50_32x4d_baseline OOF = 94.98060475767632\n",
      "Classwise_acc for resnext50_32x4d_baseline = [84.8512173128945, 93.34264432029795, 91.14561477129669, 98.22961781019679, 87.71186440677965]\n",
      "Accuracy score for resnext50_baseline_v2 OOF = 91.62499415805954\n",
      "Classwise_acc for resnext50_baseline_v2 = [69.99182338511855, 90.10880316518298, 87.90820829655782, 96.26175197731682, 81.88405797101449]\n",
      "Accuracy score for vit_baseline OOF = 93.76080758984905\n",
      "Classwise_acc for vit_baseline = [84.375, 91.4577530176416, 90.79646017699115, 96.45669291338582, 87.78904665314403]\n",
      "Accuracy score for eff_b3_baseline OOF = 90.94265551245502\n",
      "Classwise_acc for eff_b3_baseline = [76.53806047966631, 86.80037313432835, 84.08231835363293, 96.09632067005684, 79.18142463597009]\n",
      "Accuracy score for eff_b4_baseline OOF = 90.98939103612655\n",
      "Classwise_acc for eff_b4_baseline = [69.45642795513373, 85.4954954954955, 87.71377137713772, 96.37757402675484, 80.04016064257029]\n"
     ]
    }
   ],
   "source": [
    "#print(np.array_equal(csv0.files.values, csv1.files.values))\n",
    "#print(np.array_equal(csv0.files.values, csv2.files.values))\n",
    "#print(np.array_equal(csv0.files.values, csv3.files.values))\n",
    "#print(np.array_equal(csv0.files.values, csv4.files.values))\n",
    "\n",
    "get_oof_stats(csv0, 'resnext50_32x4d_baseline')\n",
    "#[0.886682, 0.899065, 0.892732, 0.888525, 0.892966], 0.891994\n",
    "\n",
    "get_oof_stats(csv1, 'resnext50_baseline_v2')\n",
    "# [0.893692, 0.901168, 0.896237, 0.888759, 0.8960037], 0.89517194\n",
    "\n",
    "get_oof_stats(csv2, 'vit_baseline')\n",
    "#[0.8929906, 0.894626, 0.887357, 0.883384, 0.887591], 0.8891897199\n",
    "\n",
    "get_oof_stats(csv3, 'eff_b3_baseline')\n",
    "# [0.893224, 0.8981308, 0.8927319, 0.886655, 0.887123], 0.89157294\n",
    "\n",
    "get_oof_stats(csv4, 'eff_b4_baseline')\n",
    "# [0.8887850, 0.8957943, 0.8913297, 0.8836176, 0.8887590], 0.88965712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_CSV = [csv0, csv1, csv2, csv3, csv4]\n",
    "OOF = oof_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 21397, 5)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros(( len(OOF), len(OOF_CSV[0]), 5))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(OOF)):\n",
    "    x[k, :, :] = OOF_CSV[k].iloc[:, 4:].values\n",
    "TRUE = OOF_CSV[0].label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, ..., 1, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 has OOF acc_score = 0.9498\n",
      "Model 1 has OOF acc_score = 0.9162\n",
      "Model 2 has OOF acc_score = 0.9376\n",
      "Model 3 has OOF acc_score = 0.9094\n",
      "Model 4 has OOF acc_score = 0.9099\n"
     ]
    }
   ],
   "source": [
    "all = []\n",
    "for k in range(x.shape[0]):\n",
    "    acc_score = accuracy_score(TRUE, np.argmax(x[k], axis=1))\n",
    "    all.append(acc_score)\n",
    "    print('Model %i has OOF acc_score = %.4f'%(k,acc_score))\n",
    "    \n",
    "m = [np.argmax(all)]; w = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble acc_score = 0.9498 by beginning with model 0\n",
      "\n",
      "(21397, 5)\n",
      "Searching for best model to add... \n",
      "0 , 1 , 2 , 3 , 4 , \n",
      "Ensemble acc_score = 0.9523 after adding model 2 with weight 0.44500. Increase of 0.00252\n",
      "\n",
      "(21397, 5)\n",
      "Searching for best model to add... \n",
      "0 , 1 , 2 , 3 , 4 , \n",
      "4.6735523671626034e-05 is less. No increase. Stopping.\n"
     ]
    }
   ],
   "source": [
    "old = np.max(all); \n",
    "\n",
    "RES = 200; \n",
    "PATIENCE = 100; \n",
    "TOL = 0.0001\n",
    "DUPLICATES = False\n",
    "\n",
    "print('Ensemble acc_score = %.4f by beginning with model %i'%(old,m[0]))\n",
    "print()\n",
    "\n",
    "for kk in range(len(OOF)):\n",
    "    \n",
    "    # BUILD CURRENT ENSEMBLE\n",
    "    md = x[m[0],:,:]\n",
    "    print(md.shape)\n",
    "    for i,k in enumerate(m[1:]):\n",
    "        md = w[i]*x[k,:,:] + (1-w[i])*md\n",
    "        \n",
    "    # FIND MODEL TO ADD\n",
    "    mx = 0; mx_k = 0; mx_w = 0\n",
    "    print('Searching for best model to add... ')\n",
    "    \n",
    "    # TRY ADDING EACH MODEL\n",
    "    for k in range(x.shape[0]):\n",
    "        print(k,', ',end='')\n",
    "        if not DUPLICATES and (k in m): continue\n",
    "            \n",
    "        # EVALUATE ADDING MODEL K WITH WEIGHTS W\n",
    "        bst_j = 0; bst = 0; ct = 0\n",
    "        for j in range(RES):\n",
    "            tmp = j/RES*x[k,:,:] + (1-j/RES)*md\n",
    "            acc = accuracy_score(TRUE,np.argmax(tmp, axis=1))\n",
    "            if acc>bst:\n",
    "                bst = acc\n",
    "                bst_j = j/RES\n",
    "            else: ct += 1\n",
    "            if ct>PATIENCE: break\n",
    "        if bst>mx:\n",
    "            mx = bst\n",
    "            mx_k = k\n",
    "            mx_w = bst_j\n",
    "            \n",
    "    # STOP IF INCREASE IS LESS THAN TOL\n",
    "    inc = mx-old\n",
    "    if inc<=TOL: \n",
    "        print(); print(f'{inc} is less. No increase. Stopping.')\n",
    "        break\n",
    "        \n",
    "    # DISPLAY RESULTS\n",
    "    print(); #print(kk,mx,mx_k,mx_w,'%.5f'%inc)\n",
    "    print('Ensemble acc_score = %.4f after adding model %i with weight %.5f. Increase of %.5f'%(mx,mx_k,mx_w,inc))\n",
    "    print()\n",
    "    \n",
    "    old = mx; m.append(mx_k); w.append(mx_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.445]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21397, 5)\n",
      "(21397,)\n",
      "Avg model prediction score = 0.936019068093658\n"
     ]
    }
   ],
   "source": [
    "x.shape\n",
    "model_avg = x.mean(axis=0)\n",
    "print(model_avg.shape)\n",
    "model_avg_predictions = np.argmax(model_avg,axis=1)\n",
    "labels = TRUE\n",
    "print(labels.shape)\n",
    "print(f'Avg model prediction score = {accuracy_score(labels, model_avg_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('oof_preds.npy', x)\n",
    "np.save('oof_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4287225 , 0.21637243, 0.19013453, 0.00523662, 0.1595339 ],\n",
       "       [0.3503957 , 0.18372487, 0.18679062, 0.06341194, 0.21567686],\n",
       "       [0.5320639 , 0.14809611, 0.15941694, 0.06226701, 0.09815604],\n",
       "       [0.28049955, 0.14849293, 0.26587525, 0.02380693, 0.28132537],\n",
       "       [0.34316963, 0.21031588, 0.15508245, 0.00797882, 0.2834532 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros((x.shape[1], 25))\n",
    "for i in range(x.shape[1]):\n",
    "    output[i] = x[:,i,:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4287225 , 0.21637243, 0.19013453, 0.00523662, 0.1595339 ,\n",
       "       0.3503957 , 0.18372487, 0.18679062, 0.06341194, 0.21567686,\n",
       "       0.5320639 , 0.14809611, 0.15941694, 0.06226701, 0.09815604,\n",
       "       0.28049955, 0.14849293, 0.26587525, 0.02380693, 0.28132537,\n",
       "       0.34316963, 0.21031588, 0.15508245, 0.00797882, 0.2834532 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(lyft_kaggle)",
   "language": "python",
   "name": "lyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
